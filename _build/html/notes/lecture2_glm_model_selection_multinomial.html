

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Lecture 2 - Generalized Linear Models: Model Selection and Multinomial Logistic Regression &#8212; DSCI 562 - Regression II</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/exercise.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'notes/lecture2_glm_model_selection_multinomial';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Lecture 3 - Generalized Linear Models: Ordinal Logistic Regression" href="lecture3_glm_ordinal_regression.html" />
    <link rel="prev" title="Lecture 1 - Generalized Linear Models: Link Functions and Count Regression" href="lecture1-glm-link-functions-and-count-regression.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../README.html">
  
  
  
  
    
    
      
    
    
    <img src="../_static/UBC_MDS_logo.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../_static/UBC_MDS_logo.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../README.html">
                    Welcome to DSCI 562: Regression II
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Lectures</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../lecture-learning-objectives.html">Lecture Learning Objectives</a></li>
<li class="toctree-l1"><a class="reference internal" href="lecture1-glm-link-functions-and-count-regression.html">Lecture 1 - Generalized Linear Models: Link Functions and Count Regression</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Lecture 2 - Generalized Linear Models: Model Selection and Multinomial Logistic Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="lecture3_glm_ordinal_regression.html">Lecture 3 - Generalized Linear Models: Ordinal Logistic Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="lecture4_linear_mixed_effects_models.html">Lecture 4 - Linear Mixed-Effects Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="lecture5_survival_analysis.html">Lecture 5 - Survival Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="lecture6_local_regression.html">Lecture 6 - Local Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="lecture7_quantile_regression.html">Lecture 7 - Quantile Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="lecture8_missing_data.html">Lecture 8 - Missing Data</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Appendices</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="appendix-binary-log-regression.html">Binary Logistic Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="appendix-reg-cheatsheet.html">Regression Cheatsheet</a></li>
<li class="toctree-l1"><a class="reference internal" href="appendix-reg-mindmap.html">Regression Mind Map</a></li>
<li class="toctree-l1"><a class="reference internal" href="appendix-dist-cheatsheet.html">Distribution Cheatsheet</a></li>
<li class="toctree-l1"><a class="reference internal" href="appendix-greek-alphabet.html">Greek Alphabet</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">License and Code of Conduct</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../LICENSE.html">License</a></li>
<li class="toctree-l1"><a class="reference internal" href="../CODE-OF-CONDUCT.html">Code of Conduct</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.ubc.ca/MDS-2023-24/DSCI_562_regr-2_students" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.ubc.ca/MDS-2023-24/DSCI_562_regr-2_students/issues/new?title=Issue%20on%20page%20%2Fnotes/lecture2_glm_model_selection_multinomial.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/notes/lecture2_glm_model_selection_multinomial.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Lecture 2 - Generalized Linear Models: Model Selection and Multinomial Logistic Regression</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#today-s-learning-goals">Today’s Learning Goals</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#loading-libraries">Loading Libraries</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#likelihood-based-model-selection">1. Likelihood-based Model Selection</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-crabs-dataset">1.1. The Crabs Dataset</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#estimation">1.2. Estimation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#goodness-of-fit-test">1.3.  Goodness of Fit Test</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#a-note-on-the-null-deviance">A Note on the Null Deviance</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#analysis-of-deviance-for-nested-models">1.4. Analysis of Deviance for Nested Models</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#akaike-information-criterion">1.5. Akaike Information Criterion</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesian-information-criterion">1.6. Bayesian Information Criterion</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#categorical-type-responses">2. Categorical Type Responses</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#multinomial-logistic-regression">3. Multinomial Logistic Regression</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-spotify-dataset">3.1. The Spotify Dataset</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-wrangling-and-summary">3.2. Data Wrangling and Summary</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exploratory-data-analysis">3.3. Exploratory Data Analysis</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-modelling-framework">3.4. Data Modelling Framework</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#primary-intuition-of-the-multinomial-logistic-regression-model">3.4.1. Primary Intuition of the Multinomial Logistic Regression Model</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#more-than-one-logit-function">3.4.2.  More than One Logit Function</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">3.5. Estimation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#inference">3.6. Inference</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#coefficient-interpretation">3.7. Coefficient Interpretation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#predictions">3.8. Predictions</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#model-selection">3.9. Model Selection</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="lecture-2-generalized-linear-models-model-selection-and-multinomial-logistic-regression">
<h1>Lecture 2 - Generalized Linear Models: Model Selection and Multinomial Logistic Regression<a class="headerlink" href="#lecture-2-generalized-linear-models-model-selection-and-multinomial-logistic-regression" title="Permalink to this heading">#</a></h1>
<section id="today-s-learning-goals">
<h2>Today’s Learning Goals<a class="headerlink" href="#today-s-learning-goals" title="Permalink to this heading">#</a></h2>
<p>By the end of this lecture, you should be able to:</p>
<ul class="simple">
<li><p>Perform likelihood-based model selection through analysis of deviance, Akaike Information Criterion, and Bayesian Information Criterion.</p></li>
<li><p>Extend the link function concept of the generalized linear models (GLMs) to other discrete categorical responses.</p></li>
<li><p>Outline the modelling framework of the Multinomial Logistic regression.</p></li>
<li><p>Fit and interpret the Multinomial Logistic regression.</p></li>
<li><p>Use the Multinomial Logistic regression for prediction.</p></li>
</ul>
</section>
<section id="loading-libraries">
<h2>Loading Libraries<a class="headerlink" href="#loading-libraries" title="Permalink to this heading">#</a></h2>
<div class="cell tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">options</span><span class="p">(</span><span class="n">repr.matrix.max.rows</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">7</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">tidyverse</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">broom</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">glmbb</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">AER</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">bayesrules</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">cowplot</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">janitor</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">nnet</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="likelihood-based-model-selection">
<h2>1. Likelihood-based Model Selection<a class="headerlink" href="#likelihood-based-model-selection" title="Permalink to this heading">#</a></h2>
<p>In <strong>DSCI 561</strong>, you learned about <strong>model selection</strong> in Ordinary Least-Squares (OLS) via specific metrics such as the Mallow’s <span class="math notranslate nohighlight">\(C_p\)</span>, Akaike information criterion (AIC), and Bayesian information criterion (BIC). These metrics are also helpful tools to perform <strong>model selection</strong> in GLMs. Additionally, it is essential to highlight that <strong>many</strong> GLMs are estimated via maximum likelihood.</p>
<p>Having said all this, you will learn today that metrics such as AIC and BIC are likelihood-based. Hence, the concept of maximum likelihood estimation (MLE) will come into play again for model selection <strong>in many GLMs</strong>. Firstly, let us explore model selection for Poisson regression via the dataset from <a class="reference internal" href="lecture1-glm-link-functions-and-count-regression.html"><span class="doc">Lecture 1 - Generalized Linear Models: Link Functions and Count Regression</span></a>.</p>
<section id="the-crabs-dataset">
<h3>1.1. The Crabs Dataset<a class="headerlink" href="#the-crabs-dataset" title="Permalink to this heading">#</a></h3>
<figure class="align-default" id="id2">
<a class="reference internal image-reference" href="../_images/crab.png"><img alt="../_images/crab.png" src="../_images/crab.png" style="height: 350px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 6 </span><span class="caption-text">Hello! I’m the Crab, again!</span><a class="headerlink" href="#id2" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>The data frame <code class="docutils literal notranslate"><span class="pre">crabs</span></code> (<a class="reference external" href="https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1439-0310.1996.tb01099.x">Brockmann, 1996</a>) is a dataset detailing the <strong>counts of satellite male crabs</strong> residing around a female crab nest. The code below renames the original response’s name, <code class="docutils literal notranslate"><span class="pre">satell</span></code>, to <code class="docutils literal notranslate"><span class="pre">n_males</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">data</span><span class="p">(</span><span class="n">crabs</span><span class="p">)</span>
<span class="n">crabs</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">crabs</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">  </span><span class="nf">rename</span><span class="p">(</span><span class="n">n_males</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">satell</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">  </span><span class="n">dplyr</span><span class="o">::</span><span class="nf">select</span><span class="p">(</span><span class="o">-</span><span class="n">y</span><span class="p">)</span>
<span class="n">crabs</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="dataframe">
<caption>A data.frame: 173 × 5</caption>
<thead>
	<tr><th scope=col>color</th><th scope=col>spine</th><th scope=col>width</th><th scope=col>n_males</th><th scope=col>weight</th></tr>
	<tr><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th></tr>
</thead>
<tbody>
	<tr><td>medium</td><td>bad </td><td>28.3</td><td>8</td><td>3050</td></tr>
	<tr><td>dark  </td><td>bad </td><td>22.5</td><td>0</td><td>1550</td></tr>
	<tr><td>light </td><td>good</td><td>26.0</td><td>9</td><td>2300</td></tr>
	<tr><td>dark  </td><td>bad </td><td>24.8</td><td>0</td><td>2100</td></tr>
	<tr><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td></tr>
	<tr><td>light </td><td>good  </td><td>28.0</td><td>0</td><td>2625</td></tr>
	<tr><td>darker</td><td>bad   </td><td>27.0</td><td>0</td><td>2625</td></tr>
	<tr><td>medium</td><td>middle</td><td>24.5</td><td>0</td><td>2000</td></tr>
</tbody>
</table>
</div></div>
</div>
<div class="admonition-the-crabs-dataset admonition">
<p class="admonition-title">The Crabs Dataset</p>
<p>The data frame <code class="docutils literal notranslate"><span class="pre">crabs</span></code> contains 173 observations on horseshoe crabs (Limulus polyphemus). The response is the count of male crabs (<code class="docutils literal notranslate"><span class="pre">n_males</span></code>) around a female breeding nest. It is subject to four explanatory variables: <code class="docutils literal notranslate"><span class="pre">color</span></code> of the prosoma with four levels (nominal factor-type), the condition of the posterior <code class="docutils literal notranslate"><span class="pre">spine</span></code> with three levels (nominal factor-type), the continuous variables carapace <code class="docutils literal notranslate"><span class="pre">width</span></code> (mm), and <code class="docutils literal notranslate"><span class="pre">weight</span></code> (g).</p>
</div>
</section>
<section id="estimation">
<h3>1.2. Estimation<a class="headerlink" href="#estimation" title="Permalink to this heading">#</a></h3>
<p><strong>To perform model selection</strong>, let us estimate two Poisson regression models with <code class="docutils literal notranslate"><span class="pre">n_males</span></code> as a response. <strong>Model 1</strong> will only have the continuous carapace <code class="docutils literal notranslate"><span class="pre">width</span></code> (<span class="math notranslate nohighlight">\(X_{\texttt{width}_i}\)</span>) as a regressor, whereas <strong>Model 2</strong> will have carapace <code class="docutils literal notranslate"><span class="pre">width</span></code> (<span class="math notranslate nohighlight">\(X_{\texttt{width}_i}\)</span>) and <code class="docutils literal notranslate"><span class="pre">color</span></code> of the prosoma (with dummy variables <span class="math notranslate nohighlight">\(X_{\texttt{color_darker}_i}\)</span>, <span class="math notranslate nohighlight">\(X_{\texttt{color_light}_i}\)</span>, and <span class="math notranslate nohighlight">\(X_{\texttt{color_medium}_i}\)</span>).</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
\textbf{Model 1:} &amp; \\ 
&amp; h(\lambda_i) = \log(\lambda_i) = \beta_0 + \beta_1 X_{\texttt{width}_i}. \\
\textbf{Model 2:} &amp; \\ 
&amp; h(\lambda_i) = \log (\lambda_i) = \beta_0 + \beta_1 X_{\texttt{width}_i} + \beta_2 X_{\texttt{color_darker}_i} + \beta_3 X_{\texttt{color_light}_i} + \beta_4 X_{\texttt{color_medium}_i}.
\end{align*}\end{split}\]</div>
<p>Then, via <code class="docutils literal notranslate"><span class="pre">glm()</span></code> and <code class="docutils literal notranslate"><span class="pre">crabs</span></code>, we obtain our regression estimates.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">poisson_model</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">glm</span><span class="p">(</span><span class="n">n_males</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">width</span><span class="p">,</span><span class="w"> </span><span class="n">family</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">poisson</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">crabs</span><span class="p">)</span>
<span class="n">poisson_model_2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">glm</span><span class="p">(</span><span class="n">n_males</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">width</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">color</span><span class="p">,</span><span class="w"> </span><span class="n">family</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">poisson</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">crabs</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Since we are digging into model selection, let us keep in mind the below <strong>main statistical inquiry</strong>.</p>
<div class="admonition-main-statistical-inquiry admonition">
<p class="admonition-title">Main statistical inquiry</p>
<p>We want to determine which Poisson regression model fits the data better: <strong>Model 1</strong> or <strong>Model 2</strong>.</p>
</div>
</section>
<section id="goodness-of-fit-test">
<h3>1.3.  Goodness of Fit Test<a class="headerlink" href="#goodness-of-fit-test" title="Permalink to this heading">#</a></h3>
<p>The <strong>deviance</strong> (<span class="math notranslate nohighlight">\(D_k\)</span>) criterion can be used to compare a given model with <span class="math notranslate nohighlight">\(k\)</span> regressors with that of a <strong>baseline model</strong>.</p>
<div class="tip admonition">
<p class="admonition-title">Definition of a Saturated or Full Model in Poisson Regression</p>
<p>The usual <strong>baseline model</strong> is the <strong>saturated</strong> or <strong>full model</strong>, which perfectly fits the data because it allows a distinct Poisson mean <span class="math notranslate nohighlight">\(\lambda_i\)</span> for the <span class="math notranslate nohighlight">\(i\)</span>th observation in the training dataset (<span class="math notranslate nohighlight">\(i = 1, \dots, n\)</span>), <strong>unrelated to the <span class="math notranslate nohighlight">\(k\)</span> regressors</strong>.</p>
</div>
<p>The <strong>maximized likelihood</strong> of this full model is denoted as <span class="math notranslate nohighlight">\(\hat{\mathscr{l}}_f\)</span>. Now, let <span class="math notranslate nohighlight">\(\hat{\mathscr{l}}_k\)</span> be the value of the maximized likelihood computed from our dataset of <span class="math notranslate nohighlight">\(n\)</span> observations with <span class="math notranslate nohighlight">\(k\)</span> regressors.</p>
<p>We can compare the fits provided by these two models by the deviance <span class="math notranslate nohighlight">\(D_k\)</span> given by</p>
<div class="math notranslate nohighlight" id="equation-deviance-general">
<span class="eqno">(13)<a class="headerlink" href="#equation-deviance-general" title="Permalink to this equation">#</a></span>\[D_k = -2 \log \left( \frac{\hat{\mathscr{l}}_k}{\hat{\mathscr{l}}_f} \right) =  -2 \left[ \log \left( \hat{\mathscr{l}}_k \right) - \log \left( \hat{\mathscr{l}}_f \right) \right].\]</div>
<p>Note that <span class="math notranslate nohighlight">\(D_k\)</span> expresses <strong>how much our given model deviates from the full model on log-likelihood scale</strong>. This metric is interpreted as follows:</p>
<ul class="simple">
<li><p><strong>Large values</strong> of <span class="math notranslate nohighlight">\(D_k\)</span> arise when <span class="math notranslate nohighlight">\(\hat{\mathscr{l}}_k\)</span> is small relative to <span class="math notranslate nohighlight">\(\hat{\mathscr{l}}_f\)</span>, indicating that <strong>our given model fits the data poorly compared to the baseline model</strong>.</p></li>
<li><p><strong>Small values</strong> of <span class="math notranslate nohighlight">\(D_k\)</span> arise when <span class="math notranslate nohighlight">\(\hat{\mathscr{l}}_k\)</span> is similar to <span class="math notranslate nohighlight">\(\hat{\mathscr{l}}_f\)</span>, indicating that <strong>our given model provides a good fit to the data compared to the baseline model</strong>.</p></li>
</ul>
<p><strong>Specifically for Poisson regression with <span class="math notranslate nohighlight">\(k\)</span> regressors</strong>, it can be shown that <span class="math notranslate nohighlight">\(D_k\)</span> <a class="reference internal" href="#equation-deviance-general">(13)</a> is defined as follows:</p>
<div class="math notranslate nohighlight" id="equation-deviance-poisson">
<span class="eqno">(14)<a class="headerlink" href="#equation-deviance-poisson" title="Permalink to this equation">#</a></span>\[\begin{split}\begin{gather}
\hat{\lambda}_i = \exp{\left( \hat{\beta_0} + \hat{\beta}_1 x_{i,1} + \dots + \hat{\beta}_k x_{i,k} \right)} \\
D_k = 2 \sum_{i = 1}^n \left[ y_i \log \left( \frac{y_i}{\hat{\lambda}_i} \right) - \left( y_i - \hat{\lambda}_i \right) \right]
\end{gather}\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(y_i\)</span> is the <span class="math notranslate nohighlight">\(i\)</span>th observed response in the training set of size <span class="math notranslate nohighlight">\(n\)</span>. Note that when <span class="math notranslate nohighlight">\(y_i = 0\)</span> counts, then <span class="math notranslate nohighlight">\(\log \left( \frac{y_i}{\hat{\lambda}_i} \right)\)</span> is assumed as <span class="math notranslate nohighlight">\(0\)</span>.</p>
<div class="tip admonition">
<p class="admonition-title">Definition of Goodness of Fit</p>
<p>Equation <a class="reference internal" href="#equation-deviance-poisson">(14)</a> depicts the agreement of our model with <span class="math notranslate nohighlight">\(k\)</span> regressors to the observed data. Hence, we can use <a class="reference internal" href="#equation-deviance-poisson">(14)</a> to test the goodness of fit; i.e., <strong>whether our fitted model fits the data better than the saturated model, which makes it correctly specified (with a level of significance <span class="math notranslate nohighlight">\(\alpha\)</span>!)</strong>.</p>
<p>The hypothesis are the following:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{gather*}
H_0: \text{Our}\textbf{ Model with $k$ regressors} \text{ fits the data better than the } \textbf{Saturated Model} \\
H_a: \text{otherwise.}
\end{gather*}\end{split}\]</div>
</div>
<p>Let us test our <code class="docutils literal notranslate"><span class="pre">poisson_model_2</span></code>:</p>
<div class="math notranslate nohighlight">
\[h(\lambda_i) = \log (\lambda_i) = \beta_0 + \beta_1 X_{\texttt{width}_i} + \beta_2 X_{\texttt{color_darker}_i} + \beta_3 X_{\texttt{color_light}_i} + \beta_4 X_{\texttt{color_medium}_i}.\]</div>
<p>We cannot use <code class="docutils literal notranslate"><span class="pre">anova()</span></code> to perform this hypothesis testing. We will have to do it manually via <code class="docutils literal notranslate"><span class="pre">glance()</span></code>,</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">summary_poisson_model_2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">glance</span><span class="p">(</span><span class="n">poisson_model_2</span><span class="p">)</span>
<span class="n">summary_poisson_model_2</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="dataframe">
<caption>A tibble: 1 × 8</caption>
<thead>
	<tr><th scope=col>null.deviance</th><th scope=col>df.null</th><th scope=col>logLik</th><th scope=col>AIC</th><th scope=col>BIC</th><th scope=col>deviance</th><th scope=col>df.residual</th><th scope=col>nobs</th></tr>
	<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th></tr>
</thead>
<tbody>
	<tr><td>632.7917</td><td>172</td><td>-457.3212</td><td>924.6425</td><td>940.4089</td><td>559.3448</td><td>168</td><td>173</td></tr>
</tbody>
</table>
</div></div>
</div>
<p>Column <code class="docutils literal notranslate"><span class="pre">deviance</span></code> provides <span class="math notranslate nohighlight">\(D_k\)</span> and is formally called <strong>residual deviance</strong>, which is the <strong>test statistic</strong>. <strong>Asymptotically</strong>, we have the following <strong>null distribution</strong>:</p>
<div class="math notranslate nohighlight">
\[
D_k \sim \chi^2_{n - (k + 1)}.
\]</div>
<p>The degrees of freedom (column <code class="docutils literal notranslate"><span class="pre">df.residual</span></code> in our <code class="docutils literal notranslate"><span class="pre">glance()</span></code> output) are the <strong>difference between the training set size <span class="math notranslate nohighlight">\(n\)</span> and the number of regression parameters in our model (including the intercept <span class="math notranslate nohighlight">\(\beta_0\)</span>).</strong></p>
<p>Let us obtain the corresponding <span class="math notranslate nohighlight">\(p\text{-value}\)</span> for this test. We can do it using <code class="docutils literal notranslate"><span class="pre">pchisq()</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">pchisq</span><span class="p">(</span><span class="n">summary_poisson_model_2</span><span class="o">$</span><span class="n">deviance</span><span class="p">,</span>
<span class="w">  </span><span class="n">df</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">summary_poisson_model_2</span><span class="o">$</span><span class="n">df.residual</span><span class="p">,</span>
<span class="w">  </span><span class="n">lower.tail</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">1.47103669470051e-43</div></div>
</div>
<p>We obtain a <span class="math notranslate nohighlight">\(p\text{-value} &lt; .001\)</span>, which gives statistical evidence to state that our <code class="docutils literal notranslate"><span class="pre">poisson_model_2</span></code> is <strong>not</strong> correctly specified when compared to the saturated model.</p>
<section id="a-note-on-the-null-deviance">
<h4>A Note on the Null Deviance<a class="headerlink" href="#a-note-on-the-null-deviance" title="Permalink to this heading">#</a></h4>
<p>The above <code class="docutils literal notranslate"><span class="pre">glance()</span></code> output contains a metric call <code class="docutils literal notranslate"><span class="pre">null.deviance</span></code>. This metric comes from a Poisson regression model which is only estimated with an intercept, i.e., <span class="math notranslate nohighlight">\(\hat{\beta}_{0}\)</span>; let us call it <span class="math notranslate nohighlight">\(D_0\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{gather}
\hat{\lambda}_i = \exp{\left( \hat{\beta_0} \right)} \\
D_0 = 2 \sum_{i = 1}^n \left[ y_i \log \left( \frac{y_i}{\hat{\lambda}_i} \right) - \left( y_i - \hat{\lambda}_i \right) \right]
\end{gather}\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(y_i\)</span> is the <span class="math notranslate nohighlight">\(i\)</span>th observed response in the training set of size <span class="math notranslate nohighlight">\(n\)</span>. Note that when <span class="math notranslate nohighlight">\(y_i = 0\)</span> counts, then <span class="math notranslate nohighlight">\(\log \left( \frac{y_i}{\hat{\lambda}_i} \right)\)</span> is assumed as <span class="math notranslate nohighlight">\(0\)</span>.</p>
<p>Moreover, <code class="docutils literal notranslate"><span class="pre">df.null</span></code> indicates the degrees of freedom of this model, which are <span class="math notranslate nohighlight">\(n - 1 = 173 - 1 = 172\)</span> (<strong>the difference between the training set size <span class="math notranslate nohighlight">\(n\)</span> and the number of regression parameters in the null model</strong>; which is <span class="math notranslate nohighlight">\(1\)</span> in this case, i.e., <span class="math notranslate nohighlight">\(\beta_0\)</span>).</p>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>A null model is different from a <strong>saturated/baseline/full model</strong>. It is importat to recall that the <strong>saturated/baseline/full model</strong> is a model that perfectly fits the training data, which could be viewed as basically interpolating all the training data points <strong>without caring about any regressor at all</strong>. Mathematically, the saturated model implicates having an exact prediction <span class="math notranslate nohighlight">\(\hat{\lambda}_i\)</span> for each <span class="math notranslate nohighlight">\(y_i\)</span>:</p>
<div class="math notranslate nohighlight">
\[\hat{\lambda}_i = y_i \text{ for } i = 1, \dots, n.\]</div>
</div>
</section>
</section>
<section id="analysis-of-deviance-for-nested-models">
<h3>1.4. Analysis of Deviance for Nested Models<a class="headerlink" href="#analysis-of-deviance-for-nested-models" title="Permalink to this heading">#</a></h3>
<p>We can use analysis of deviance for model selection when two models are nested. Hence, we will test our two Poisson models:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
\textbf{Model 1:} &amp; \\ 
&amp; h(\lambda_i) = \log(\lambda_i) = \beta_0 + \beta_1 X_{\texttt{width}_i}. \\
\textbf{Model 2:} &amp; \\ 
&amp; h(\lambda_i) = \log (\lambda_i) = \beta_0 + \beta_1 X_{\texttt{width}_i} + \beta_2 X_{\texttt{color_darker}_i} + \beta_3 X_{\texttt{color_light}_i} + \beta_4 X_{\texttt{color_medium}_i}.
\end{align*}\end{split}\]</div>
<p>This specific model selection will involve a hypothesis testing. The hypotheses are:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{gather*}
H_0: \textbf{Model 1} \text{ fits the data better than } \textbf{Model 2} \\
H_a: \textbf{Model 2} \text{ fits the data better than } \textbf{Model 1}.
\end{gather*}\end{split}\]</div>
<p>We have to use the multipurpose function <code class="docutils literal notranslate"><span class="pre">anova()</span></code> in the following way:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">round</span><span class="p">(</span><span class="nf">anova</span><span class="p">(</span><span class="n">poisson_model</span><span class="p">,</span>
<span class="w">  </span><span class="n">poisson_model_2</span><span class="p">,</span>
<span class="w">  </span><span class="n">test</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Chi&quot;</span>
<span class="p">),</span><span class="w"> </span><span class="m">4</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="dataframe">
<caption>A anova: 2 × 5</caption>
<thead>
	<tr><th></th><th scope=col>Resid. Df</th><th scope=col>Resid. Dev</th><th scope=col>Df</th><th scope=col>Deviance</th><th scope=col>Pr(&gt;Chi)</th></tr>
	<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>
</thead>
<tbody>
	<tr><th scope=row>1</th><td>171</td><td>567.8786</td><td>NA</td><td>    NA</td><td>    NA</td></tr>
	<tr><th scope=row>2</th><td>168</td><td>559.3448</td><td> 3</td><td>8.5338</td><td>0.0362</td></tr>
</tbody>
</table>
</div></div>
</div>
<p>Let <span class="math notranslate nohighlight">\(D_2\)</span> be the deviance (column <code class="docutils literal notranslate"><span class="pre">Resid.</span> <span class="pre">Dev</span></code>) for <strong>Model 2</strong> (<code class="docutils literal notranslate"><span class="pre">poisson_model_2</span></code>) in row 2 and <span class="math notranslate nohighlight">\(D_1\)</span> (column <code class="docutils literal notranslate"><span class="pre">Resid.</span> <span class="pre">Dev</span></code>) the deviance for <strong>Model 1</strong> (<code class="docutils literal notranslate"><span class="pre">poisson_model</span></code>) in row 1. The <strong>test statistic</strong> <span class="math notranslate nohighlight">\(\Delta_D\)</span> (column <code class="docutils literal notranslate"><span class="pre">Deviance</span></code>) for the analysis of deviance is given by:</p>
<div class="math notranslate nohighlight">
\[
\Delta_D = D_1 - D_2 \sim \chi^2_{3},
\]</div>
<p>which <strong>asymptotically</strong> (i.e., <span class="math notranslate nohighlight">\(n \rightarrow \infty\)</span>) is <a class="reference external" href="https://www.math.wm.edu/~leemis/chart/UDR/PDFs/Chisquare.pdf"><strong>Chi-squared distributed</strong></a> with <span class="math notranslate nohighlight">\(3\)</span> degrees of freedom (column <code class="docutils literal notranslate"><span class="pre">Df</span></code>) under <span class="math notranslate nohighlight">\(H_0\)</span> <strong>for this specific case</strong>.</p>
<p>We obtain a <span class="math notranslate nohighlight">\(p\text{-value} &lt; .05\)</span>, column <code class="docutils literal notranslate"><span class="pre">Pr(&gt;Chi)</span></code>, which gives us evidence to reject <span class="math notranslate nohighlight">\(H_0\)</span> with <span class="math notranslate nohighlight">\(\alpha = 0.05\)</span>. Hence, we do have evidence to conclude that <code class="docutils literal notranslate"><span class="pre">poisson_model_2</span></code> fits the data better than <code class="docutils literal notranslate"><span class="pre">poisson_model</span></code>. Therefore, <strong>in the context of model selection</strong>, we would choose <code class="docutils literal notranslate"><span class="pre">poisson_model_2</span></code>, that also includes the <code class="docutils literal notranslate"><span class="pre">color</span></code> of the prosoma.</p>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>In general, the degrees of freedom are the <strong>regression parameters of difference between both models</strong> (this has an impact on the factor-type explanatory variables with more than one dummy variable). In this example, <strong>Model 2</strong> has three additional parameters: <span class="math notranslate nohighlight">\(\beta_2\)</span>, <span class="math notranslate nohighlight">\(\beta_3\)</span>, and <span class="math notranslate nohighlight">\(\beta_4\)</span>.</p>
<p>Formally, this nested hypothesis testing is called the <strong>likelihood-ratio test</strong>.</p>
</div>
</section>
<section id="akaike-information-criterion">
<h3>1.5. Akaike Information Criterion<a class="headerlink" href="#akaike-information-criterion" title="Permalink to this heading">#</a></h3>
<p><strong>One of the drawbacks of the analysis of deviance</strong> is that it only allows to test <strong>nested</strong> regression models. Fortunately, we have alternatives for model selection. <strong>The AIC makes possible to compare models that are either nested or not.</strong> For a model with <span class="math notranslate nohighlight">\(k\)</span> model terms and a deviance <span class="math notranslate nohighlight">\(D_k\)</span> is defined as:</p>
<div class="math notranslate nohighlight">
\[\begin{equation}
\mbox{AIC}_k = D_k + 2k.
\end{equation}\]</div>
<p>Models with <strong>smaller</strong> values of <span class="math notranslate nohighlight">\(\mbox{AIC}_k\)</span> are preferred. That said, <span class="math notranslate nohighlight">\(\mbox{AIC}_k\)</span> favours models with small values of <span class="math notranslate nohighlight">\(D_k\)</span>.</p>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>However, <span class="math notranslate nohighlight">\(\mbox{AIC}_k\)</span> penalizes for including more regressors in the model. Hence, it discourages overfitting, which is key in model selection.</p>
<p>This is why we select that model with the smallest <span class="math notranslate nohighlight">\(\mbox{AIC}_k\)</span>.</p>
</div>
<p>The function <code class="docutils literal notranslate"><span class="pre">glance()</span></code> shows us the <span class="math notranslate nohighlight">\(\mbox{AIC}_k\)</span> by model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">glance</span><span class="p">(</span><span class="n">poisson_model</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="nf">mutate_if</span><span class="p">(</span><span class="n">is.numeric</span><span class="p">,</span><span class="w"> </span><span class="n">round</span><span class="p">,</span><span class="w"> </span><span class="m">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="dataframe">
<caption>A tibble: 1 × 8</caption>
<thead>
	<tr><th scope=col>null.deviance</th><th scope=col>df.null</th><th scope=col>logLik</th><th scope=col>AIC</th><th scope=col>BIC</th><th scope=col>deviance</th><th scope=col>df.residual</th><th scope=col>nobs</th></tr>
	<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>
</thead>
<tbody>
	<tr><td>632.792</td><td>172</td><td>-461.588</td><td>927.176</td><td>933.483</td><td>567.879</td><td>171</td><td>173</td></tr>
</tbody>
</table>
</div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">glance</span><span class="p">(</span><span class="n">poisson_model_2</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="nf">mutate_if</span><span class="p">(</span><span class="n">is.numeric</span><span class="p">,</span><span class="w"> </span><span class="n">round</span><span class="p">,</span><span class="w"> </span><span class="m">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="dataframe">
<caption>A tibble: 1 × 8</caption>
<thead>
	<tr><th scope=col>null.deviance</th><th scope=col>df.null</th><th scope=col>logLik</th><th scope=col>AIC</th><th scope=col>BIC</th><th scope=col>deviance</th><th scope=col>df.residual</th><th scope=col>nobs</th></tr>
	<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>
</thead>
<tbody>
	<tr><td>632.792</td><td>172</td><td>-457.321</td><td>924.642</td><td>940.409</td><td>559.345</td><td>168</td><td>173</td></tr>
</tbody>
</table>
</div></div>
</div>
<blockquote>
<div><p>Following the results of the <code class="docutils literal notranslate"><span class="pre">AIC</span></code> column, we choose <code class="docutils literal notranslate"><span class="pre">poisson_model_2</span></code> over <code class="docutils literal notranslate"><span class="pre">poisson_model</span></code>.</p>
</div></blockquote>
</section>
<section id="bayesian-information-criterion">
<h3>1.6. Bayesian Information Criterion<a class="headerlink" href="#bayesian-information-criterion" title="Permalink to this heading">#</a></h3>
<p>An alternative to AIC is the Bayesian Information Criterion (BIC). <strong>The BIC also makes possible to compare models that are either nested or not.</strong> For a model with <span class="math notranslate nohighlight">\(k\)</span> regressors, <span class="math notranslate nohighlight">\(n\)</span> observations used for training, and a deviance <span class="math notranslate nohighlight">\(D_k\)</span>; it is defined as:</p>
<div class="math notranslate nohighlight">
\[\mbox{BIC}_k = D_k + k \log (n).\]</div>
<p>Models with <strong>smaller</strong> values of <span class="math notranslate nohighlight">\(\mbox{BIC}_k\)</span> are preferred. That said, <span class="math notranslate nohighlight">\(\mbox{BIC}_k\)</span> also favours models with small values of <span class="math notranslate nohighlight">\(D_k\)</span>.</p>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>The differences between AIC and BIC will be more pronounced in datasets with large sample sizes <span class="math notranslate nohighlight">\(n\)</span>. As the BIC penalty of <span class="math notranslate nohighlight">\(k \log (n)\)</span> will always be larger than the AIC penalty of <span class="math notranslate nohighlight">\(2k\)</span> when <span class="math notranslate nohighlight">\(n &gt; 7\)</span>, <strong>BIC tends to select models with fewer regressors than AIC</strong>.</p>
</div>
<blockquote>
<div><p>Following the results of the <code class="docutils literal notranslate"><span class="pre">AIC</span></code> column, we already chose <code class="docutils literal notranslate"><span class="pre">poisson_model_2</span></code> over <code class="docutils literal notranslate"><span class="pre">poisson_model</span></code>. Nonetheless, the <code class="docutils literal notranslate"><span class="pre">BIC</span></code> is penalizing the <code class="docutils literal notranslate"><span class="pre">poisson_model_2</span></code> for having more model parameters, so <code class="docutils literal notranslate"><span class="pre">poisson_model</span></code> would be chosen under this criterion.</p>
</div></blockquote>
</section>
</section>
<section id="categorical-type-responses">
<h2>2. Categorical Type Responses<a class="headerlink" href="#categorical-type-responses" title="Permalink to this heading">#</a></h2>
<p>So far, we have dealt with continuous, binary, and count responses using OLS, Binary Logistic, Poisson (or Negative Binomial) regressions, respectively.</p>
<p>Nonetheless, we have not covered those <strong>discrete responses with more than two categories</strong>. Recall that the nature of these responses could be:</p>
<ul class="simple">
<li><p><strong>Nominal.</strong> We have categories that do not follow any specific order—for example, the type of dwelling according to the Canadian census: <em>single-detached house</em>, <em>semi-detached house</em>, <em>row house</em>, <em>apartment</em>, and <em>mobile home</em>.</p></li>
<li><p><strong>Ordinal.</strong> The categories, in this case, follow a specific order—for example, a Likert scale of survey items: <em>strongly disagree</em>, <em>disagree</em>, <em>neutral</em>, <em>agree</em>, and <em>strongly agree</em>.</p></li>
</ul>
<p>Moreover, you have seen in <strong>DSCI 561</strong> that <strong>using OLS to fit a model with a binary response variable has important problems</strong>. Frequently, the restricted range is not respected in terms of the fitted values from our training set or if we use the fitted model to make predictions on a different testing set. So then, we use Binary Logistic regression.</p>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>Recall that Binary Logistic regression’s link function (the <strong>logarithm of the odds</strong> or <strong>logit function</strong>) restricts the corresponding probability of success to a range between <span class="math notranslate nohighlight">\(0\)</span> and <span class="math notranslate nohighlight">\(1\)</span> while relating it to the systematic component (i.e., the regressors and its corresponding parameters!).</p>
<p>Nevertheless, this GLM has an important limitation: it is restricted to a Bernoulli trial with only two classes (<strong>success</strong> or <strong>failure</strong>).</p>
</div>
<p>Then, we might wonder: <strong>what if we have more than two classes in the categorical response?</strong></p>
<p>Let us pave the way to two new GLMs to address this matter: <strong>Multinomial and Ordinal Logistic regressions</strong>.</p>
</section>
<section id="multinomial-logistic-regression">
<h2>3. Multinomial Logistic Regression<a class="headerlink" href="#multinomial-logistic-regression" title="Permalink to this heading">#</a></h2>
<p>Moving along with GLMs, let us expand the regression mind map as in <a class="reference internal" href="#reg-mindmap-3"><span class="std std-numref">Fig. 7</span></a> to include a new model: <strong>Multinomial Logistic regression</strong>.</p>
<div class="full-width docutils">
<figure class="align-default" id="reg-mindmap-3">
<a class="reference internal image-reference" href="../_images/reg-mindmap-3.png"><img alt="../_images/reg-mindmap-3.png" src="../_images/reg-mindmap-3.png" style="height: 1000px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 7 </span><span class="caption-text">Expanded regression modelling mind map.</span><a class="headerlink" href="#reg-mindmap-3" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
</div>
<p><strong>Multinomial Logistic regression</strong> is a maximum likelihood-based GLM that addresses inferential (and predictive!) inquiries where the response is <strong>categorical</strong> and <strong>nominal</strong>. To illustrate the use of this GLM, let us introduce an adequate dataset.</p>
<section id="the-spotify-dataset">
<h3>3.1. The Spotify Dataset<a class="headerlink" href="#the-spotify-dataset" title="Permalink to this heading">#</a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">spotify</span></code> dataset is a sample of <span class="math notranslate nohighlight">\(n = 350\)</span> songs with different variables by column.</p>
<div class="admonition-the-spotify-dataset admonition">
<p class="admonition-title">The Spotify Dataset</p>
<p>This data comes in the <code class="docutils literal notranslate"><span class="pre">bayesrules</span></code> package. Its description is the following:</p>
<blockquote>
<div><p><em>A sub-sample of the Spotify song data originally collected by Kaylin Pavlik (kaylinquest) and distributed through the <code class="docutils literal notranslate"><span class="pre">R</span></code> for Data Science TidyTuesday project.</em></p>
</div></blockquote>
</div>
<center>        
<img src="https://storage.googleapis.com/pr-newsroom-wp/1/2018/11/Spotify_Logo_CMYK_Green.png" width="600" height="180"/>
</center>
</br><p>This dataset has 23 variables in total. The <span class="math notranslate nohighlight">\(n = 350\)</span> songs belong to 44 different artists.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">spotify</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="dataframe">
<caption>A spec_tbl_df: 350 × 23</caption>
<thead>
	<tr><th scope=col>track_id</th><th scope=col>title</th><th scope=col>artist</th><th scope=col>popularity</th><th scope=col>album_id</th><th scope=col>album_name</th><th scope=col>album_release_date</th><th scope=col>playlist_name</th><th scope=col>playlist_id</th><th scope=col>genre</th><th scope=col>⋯</th><th scope=col>key</th><th scope=col>loudness</th><th scope=col>mode</th><th scope=col>speechiness</th><th scope=col>acousticness</th><th scope=col>instrumentalness</th><th scope=col>liveness</th><th scope=col>valence</th><th scope=col>tempo</th><th scope=col>duration_ms</th></tr>
	<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>⋯</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>
</thead>
<tbody>
	<tr><td>7sYAS4CpbV90oSemgaEQat</td><td><span style=white-space:pre-wrap>On &amp; On     </span></td><td>Alok</td><td>79</td><td>2a9AGivapFES2j2ElI3odn</td><td><span style=white-space:pre-wrap>On &amp; On               </span></td><td>2019-11-22</td><td><span style=white-space:pre-wrap>Dance Room     </span></td><td>37i9dQZF1DX2ENAPP1Tyed</td><td>pop</td><td>⋯</td><td>10</td><td>-5.898</td><td>0</td><td> 7.22</td><td> 2.330</td><td>0.00138</td><td>76.10</td><td>67.0</td><td>125.070</td><td>147027</td></tr>
	<tr><td>1YSwQvw1NrEPfA0j1iY8eV</td><td>All The Lies</td><td>Alok</td><td>56</td><td>2FdyKqNeEX2H7gUhtlmJDC</td><td>All The Lies (Remixes)</td><td>2019-07-19</td><td>Cardio         </td><td>37i9dQZF1DWSJHnPb1f0X3</td><td>pop</td><td>⋯</td><td> 6</td><td>-4.777</td><td>1</td><td>17.50</td><td> 0.908</td><td>0.00000</td><td>36.60</td><td>63.4</td><td>119.972</td><td>163000</td></tr>
	<tr><td>39cmB3ZoTOLwOTq7tMNqKa</td><td>Hear Me Now </td><td>Alok</td><td>75</td><td>6fpsA5aYbVNLe6y3P49o2o</td><td>Hear Me Now           </td><td>2016      </td><td>ElectroPop 2020</td><td>4frhr6RQM2fMOm2mpvOVo6</td><td>pop</td><td>⋯</td><td>11</td><td>-7.603</td><td>1</td><td> 3.89</td><td>54.600</td><td>0.28900</td><td> 7.31</td><td>49.6</td><td>121.999</td><td>194840</td></tr>
	<tr><td>2Dnb6yPGUq0vmGtxzm3bwi</td><td>The Wall    </td><td>Alok</td><td>65</td><td>0hH9tb1b4Z87g7SHmnriKa</td><td>The Wall              </td><td>2019-06-28</td><td>Electropop     </td><td>2Z5cPJ6Z4EVZAfF08amjvL</td><td>pop</td><td>⋯</td><td>11</td><td>-2.314</td><td>1</td><td> 4.31</td><td> 0.953</td><td>6.73000</td><td> 7.32</td><td>53.6</td><td>122.943</td><td>159500</td></tr>
	<tr><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋱</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td></tr>
	<tr><td>3SmytDq4CeZ3nKE9777qEx</td><td>Save My Grave           </td><td>Zeds Dead</td><td>54</td><td>0M5oUKrfgJtfZUKdFsC4VZ</td><td>We Are Deadbeats (Vol. 4)</td><td>2020-01-14</td><td>Trap Nation       </td><td>0NCspsyf0OS4BsPgGhkQXM</td><td>rap</td><td>⋯</td><td>8</td><td>-8.101</td><td>0</td><td> 3.15</td><td>1.47000</td><td> 0.0733</td><td>15.8</td><td>12.3</td><td>108.021</td><td>222387</td></tr>
	<tr><td>606LnHssjBNoQIrxa9KTYK</td><td>Shake                   </td><td>Zeds Dead</td><td>49</td><td>2S3ydN35socDKdH6ROBhfN</td><td>Shake                    </td><td>2019-09-10</td><td>Nasty Bits        </td><td>37i9dQZF1DX2VvACCrgjrt</td><td>edm</td><td>⋯</td><td>8</td><td>-3.680</td><td>1</td><td> 6.57</td><td>0.00178</td><td>32.4000</td><td>18.0</td><td>36.6</td><td> 75.026</td><td>278400</td></tr>
	<tr><td>4kbaxfwAF2FaquuDiWSkDT</td><td>Sound Of The Underground</td><td>Zeds Dead</td><td>48</td><td>4xjytv2hkFsqSz2z8y6efp</td><td>Sound Of The Underground </td><td>2019-12-04</td><td>ELECTRO HOUSE 2020</td><td>1N5dPU0Ca9N9AwBbUeyzX5</td><td>edm</td><td>⋯</td><td>1</td><td>-0.247</td><td>1</td><td>10.40</td><td>0.32300</td><td>75.8000</td><td>11.2</td><td>19.2</td><td>170.084</td><td>248480</td></tr>
</tbody>
</table>
</div></div>
</div>
<p>We will start with an in-class question via <a class="reference external" href="https://student.iclicker.com/"><strong>iClicker</strong></a>.</p>
<div class="exercise admonition" id="lecture2-q1">

<p class="admonition-title"><span class="caption-number">Exercise 4 </span></p>
<section id="exercise-content">
<p>Having checked the description of the <code class="docutils literal notranslate"><span class="pre">spotify</span></code> dataset, suppose we want to conduct an inferential study. What would be the primary nature of our conclusions?</p>
<p><strong>A.</strong> We could draw causation conclusions across all music platforms.</p>
<p><strong>B.</strong> We could draw association conclusions on the Spotify platform.</p>
<p><strong>C.</strong> We could draw association conclusions across all music platforms.</p>
<p><strong>D.</strong> We could draw causation conclusions on the Spotify platform.</p>
</section>
</div>
<div class="admonition-main-statistical-inquiries admonition">
<p class="admonition-title">Main Statistical Inquiries</p>
<p>I am <strong>big fan</strong> of the electronic dance music (<code class="docutils literal notranslate"><span class="pre">edm</span></code>) catalogue on Spotify. Nevertheless, I do not have access to their whole song database. Still, I want to do the following:</p>
<ul class="simple">
<li><p>To statistically measure how danceable this genre is, compared to other genres on the platform, and by how much.</p></li>
<li><p>To statistically measure how euphoric this genre is, compared to other genres on the platform, and by how much.</p></li>
</ul>
</div>
</section>
<section id="data-wrangling-and-summary">
<h3>3.2. Data Wrangling and Summary<a class="headerlink" href="#data-wrangling-and-summary" title="Permalink to this heading">#</a></h3>
<p>In terms of our main statistical inquiries, we will extract these <strong>key variables by song</strong> from the <code class="docutils literal notranslate"><span class="pre">spotify</span></code> dataset:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">genre</span></code>: genre of the playlist where the song belongs (a <strong>categorical</strong> and <strong>nominal</strong> variable).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">danceability</span></code>:  a <strong>numerical</strong> score from 0 (not danceable) to 100 (danceable) based on features such as tempo, rhythm, etc.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">valence</span></code>: a <strong>numerical</strong> score from 0 (the song is more negative, sad, angry) to 100 (the song is more positive, happy, <strong>euphoric</strong>).</p></li>
</ul>
<p>We will also extract these secondary variables (<strong>not to be used in our analysis</strong>, just for having a more informative training data):</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">title</span></code>: song name.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">artist</span></code>: song artist.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">album_name</span></code>: name of the album on which the song appears.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">spotify_training</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">spotify</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">  </span><span class="nf">select</span><span class="p">(</span><span class="n">title</span><span class="p">,</span><span class="w"> </span><span class="n">artist</span><span class="p">,</span><span class="w"> </span><span class="n">album_name</span><span class="p">,</span><span class="w"> </span><span class="n">genre</span><span class="p">,</span><span class="w"> </span><span class="n">danceability</span><span class="p">,</span><span class="w"> </span><span class="n">valence</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">  </span><span class="nf">mutate</span><span class="p">(</span><span class="n">genre</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">as.factor</span><span class="p">(</span><span class="n">genre</span><span class="p">))</span>
<span class="n">spotify_training</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="dataframe">
<caption>A tibble: 350 × 6</caption>
<thead>
	<tr><th scope=col>title</th><th scope=col>artist</th><th scope=col>album_name</th><th scope=col>genre</th><th scope=col>danceability</th><th scope=col>valence</th></tr>
	<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>
</thead>
<tbody>
	<tr><td><span style=white-space:pre-wrap>On &amp; On     </span></td><td>Alok</td><td><span style=white-space:pre-wrap>On &amp; On               </span></td><td>pop</td><td>74.7</td><td>67.0</td></tr>
	<tr><td>All The Lies</td><td>Alok</td><td>All The Lies (Remixes)</td><td>pop</td><td>70.7</td><td>63.4</td></tr>
	<tr><td>Hear Me Now </td><td>Alok</td><td>Hear Me Now           </td><td>pop</td><td>77.8</td><td>49.6</td></tr>
	<tr><td>The Wall    </td><td>Alok</td><td>The Wall              </td><td>pop</td><td>68.2</td><td>53.6</td></tr>
	<tr><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td></tr>
	<tr><td>Save My Grave           </td><td>Zeds Dead</td><td>We Are Deadbeats (Vol. 4)</td><td>rap</td><td>60.4</td><td>12.3</td></tr>
	<tr><td>Shake                   </td><td>Zeds Dead</td><td>Shake                    </td><td>edm</td><td>50.1</td><td>36.6</td></tr>
	<tr><td>Sound Of The Underground</td><td>Zeds Dead</td><td>Sound Of The Underground </td><td>edm</td><td>67.5</td><td>19.2</td></tr>
</tbody>
</table>
</div></div>
</div>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>Note that factor-type <code class="docutils literal notranslate"><span class="pre">genre</span></code> has six levels (<code class="docutils literal notranslate"><span class="pre">edm</span></code> refers to <strong>electronic dance music</strong> and <code class="docutils literal notranslate"><span class="pre">r&amp;b</span></code> to <strong>rhythm and blues</strong>). Moreover, <strong>from a coding perspective</strong>, <code class="docutils literal notranslate"><span class="pre">edm</span></code> is the <strong>baseline</strong> level (it is located on the <strong>left-hand side</strong> in the <code class="docutils literal notranslate"><span class="pre">levels()</span></code> output).</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">levels</span><span class="p">(</span><span class="n">spotify_training</span><span class="o">$</span><span class="n">genre</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>
.list-inline {list-style: none; margin:0; padding: 0}
.list-inline>li {display: inline-block}
.list-inline>li:not(:last-child)::after {content: "\00b7"; padding: 0 .5ex}
</style>
<ol class=list-inline><li>'edm'</li><li>'latin'</li><li>'pop'</li><li>'r&amp;b'</li><li>'rap'</li><li>'rock'</li></ol>
</div></div>
</div>
<p>Finally, let us summarize the data by <code class="docutils literal notranslate"><span class="pre">genre</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">spotify_training</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="nf">tabyl</span><span class="p">(</span><span class="n">genre</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">  </span><span class="nf">adorn_totals</span><span class="p">(</span><span class="s">&quot;row&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">  </span><span class="nf">adorn_pct_formatting</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="dataframe">
<caption>A tabyl: 7 × 3</caption>
<thead>
	<tr><th></th><th scope=col>genre</th><th scope=col>n</th><th scope=col>percent</th></tr>
	<tr><th></th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th></tr>
</thead>
<tbody>
	<tr><th scope=row>1</th><td>edm  </td><td> 60</td><td>17.1% </td></tr>
	<tr><th scope=row>2</th><td>latin</td><td> 27</td><td>7.7%  </td></tr>
	<tr><th scope=row>3</th><td>pop  </td><td> 71</td><td>20.3% </td></tr>
	<tr><th scope=row>4</th><td><span style=white-space:pre-wrap>r&amp;b  </span></td><td>104</td><td>29.7% </td></tr>
	<tr><th scope=row>5</th><td>rap  </td><td> 62</td><td>17.7% </td></tr>
	<tr><th scope=row>6</th><td>rock </td><td> 26</td><td>7.4%  </td></tr>
	<tr><th scope=row>7</th><td>Total</td><td>350</td><td>100.0%</td></tr>
</tbody>
</table>
</div></div>
</div>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>Note that <code class="docutils literal notranslate"><span class="pre">edm</span></code> accounts for 17.1% of the whole training data. On the other hand, <code class="docutils literal notranslate"><span class="pre">latin</span></code> and <code class="docutils literal notranslate"><span class="pre">rock</span></code> account for less than 10% each. Finally, <code class="docutils literal notranslate"><span class="pre">r&amp;b</span></code> has the largest share with 29.7%.</p>
<p>Still, having checked this <code class="docutils literal notranslate"><span class="pre">genre</span></code> composition, we have an acceptable number of songs to draw inference from. Moreover, an imbalanced classification will be dealt with the distributional assumption of the Multinomial Logistic regression.</p>
</div>
</section>
<section id="exploratory-data-analysis">
<h3>3.3. Exploratory Data Analysis<a class="headerlink" href="#exploratory-data-analysis" title="Permalink to this heading">#</a></h3>
<p>As done in our previous lecture, let us take a look at the data first. Note that <code class="docutils literal notranslate"><span class="pre">genre</span></code> is a <strong>discrete nominal response</strong>, so we must be careful about the class of plots we use for exploratory data analysis (EDA). Hence, we could use the following side-by-side plots for both <code class="docutils literal notranslate"><span class="pre">danceability</span></code> and <code class="docutils literal notranslate"><span class="pre">valence</span></code>:</p>
<ul class="simple">
<li><p><strong>Boxplots.</strong></p></li>
<li><p><strong>Violin plots.</strong></p></li>
</ul>
<p>The code below creates side-by-side boxplots and violin plots, where <code class="docutils literal notranslate"><span class="pre">danceability</span></code> or <code class="docutils literal notranslate"><span class="pre">valence</span></code> are on the <span class="math notranslate nohighlight">\(y\)</span>-axis, and all categories of <code class="docutils literal notranslate"><span class="pre">genre</span></code> are on the <span class="math notranslate nohighlight">\(x\)</span>-axis. Moreover, the side-by-side violin plots show the mean of <code class="docutils literal notranslate"><span class="pre">danceability</span></code> or <code class="docutils literal notranslate"><span class="pre">valence</span></code> by <code class="docutils literal notranslate"><span class="pre">genre</span></code> as orange points.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">options</span><span class="p">(</span><span class="n">repr.plot.height</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">18</span><span class="p">,</span><span class="w"> </span><span class="n">repr.plot.width</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">20</span><span class="p">)</span>

<span class="n">genre_danceability_side_boxplots</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">spotify_training</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">  </span><span class="nf">ggplot</span><span class="p">(</span><span class="nf">aes</span><span class="p">(</span><span class="n">genre</span><span class="p">,</span><span class="w"> </span><span class="n">danceability</span><span class="p">))</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">geom_boxplot</span><span class="p">(</span><span class="nf">aes</span><span class="p">(</span><span class="n">fill</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">genre</span><span class="p">))</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">labs</span><span class="p">(</span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Danceability (0-100)&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Genre&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">ggtitle</span><span class="p">(</span><span class="s">&quot;Side-by-Side Boxplots for Danceability&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">theme</span><span class="p">(</span>
<span class="w">    </span><span class="n">plot.title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">element_text</span><span class="p">(</span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">31</span><span class="p">,</span><span class="w"> </span><span class="n">face</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;bold&quot;</span><span class="p">),</span>
<span class="w">    </span><span class="n">axis.text</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">element_text</span><span class="p">(</span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">21</span><span class="p">,</span><span class="w"> </span><span class="n">angle</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">10</span><span class="p">),</span>
<span class="w">    </span><span class="n">axis.title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">element_text</span><span class="p">(</span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">27</span><span class="p">),</span>
<span class="w">    </span><span class="n">legend.position</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;none&quot;</span>
<span class="w">  </span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">scale_fill_brewer</span><span class="p">(</span><span class="n">palette</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;BuPu&quot;</span><span class="p">)</span>

<span class="n">genre_danceability_side_violin</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">spotify_training</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">  </span><span class="nf">ggplot</span><span class="p">(</span><span class="nf">aes</span><span class="p">(</span><span class="n">genre</span><span class="p">,</span><span class="w"> </span><span class="n">danceability</span><span class="p">))</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">geom_violin</span><span class="p">(</span><span class="nf">aes</span><span class="p">(</span><span class="n">fill</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">genre</span><span class="p">))</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">labs</span><span class="p">(</span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Danceability (0-100)&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Genre&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">ggtitle</span><span class="p">(</span><span class="s">&quot;Side-by-Side Violin Plots for Danceability&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">stat_summary</span><span class="p">(</span>
<span class="w">    </span><span class="n">fun</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mean</span><span class="p">,</span><span class="w"> </span><span class="n">colour</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;orange&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">geom</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;point&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="n">shape</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">18</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">5</span>
<span class="w">  </span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">theme</span><span class="p">(</span>
<span class="w">    </span><span class="n">plot.title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">element_text</span><span class="p">(</span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">31</span><span class="p">,</span><span class="w"> </span><span class="n">face</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;bold&quot;</span><span class="p">),</span>
<span class="w">    </span><span class="n">axis.text</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">element_text</span><span class="p">(</span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">21</span><span class="p">,</span><span class="w"> </span><span class="n">angle</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">10</span><span class="p">),</span>
<span class="w">    </span><span class="n">axis.title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">element_text</span><span class="p">(</span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">27</span><span class="p">),</span>
<span class="w">    </span><span class="n">legend.position</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;none&quot;</span>
<span class="w">  </span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">scale_fill_brewer</span><span class="p">(</span><span class="n">palette</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;BuPu&quot;</span><span class="p">)</span>

<span class="n">genre_valence_side_boxplots</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">spotify_training</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">  </span><span class="nf">ggplot</span><span class="p">(</span><span class="nf">aes</span><span class="p">(</span><span class="n">genre</span><span class="p">,</span><span class="w"> </span><span class="n">valence</span><span class="p">))</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">geom_boxplot</span><span class="p">(</span><span class="nf">aes</span><span class="p">(</span><span class="n">fill</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">genre</span><span class="p">))</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">labs</span><span class="p">(</span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Valence (0-100)&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Genre&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">ggtitle</span><span class="p">(</span><span class="s">&quot;Side-by-Side Boxplots for Valence&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">theme</span><span class="p">(</span>
<span class="w">    </span><span class="n">plot.title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">element_text</span><span class="p">(</span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">31</span><span class="p">,</span><span class="w"> </span><span class="n">face</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;bold&quot;</span><span class="p">),</span>
<span class="w">    </span><span class="n">axis.text</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">element_text</span><span class="p">(</span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">21</span><span class="p">,</span><span class="w"> </span><span class="n">angle</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">10</span><span class="p">),</span>
<span class="w">    </span><span class="n">axis.title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">element_text</span><span class="p">(</span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">27</span><span class="p">),</span>
<span class="w">    </span><span class="n">legend.position</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;none&quot;</span>
<span class="w">  </span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">scale_fill_brewer</span><span class="p">(</span><span class="n">palette</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;BuPu&quot;</span><span class="p">)</span>

<span class="n">genre_valence_side_violin</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">spotify_training</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">  </span><span class="nf">ggplot</span><span class="p">(</span><span class="nf">aes</span><span class="p">(</span><span class="n">genre</span><span class="p">,</span><span class="w"> </span><span class="n">valence</span><span class="p">))</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">geom_violin</span><span class="p">(</span><span class="nf">aes</span><span class="p">(</span><span class="n">fill</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">genre</span><span class="p">))</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">labs</span><span class="p">(</span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Valence (0-100)&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Genre&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">ggtitle</span><span class="p">(</span><span class="s">&quot;Side-by-Side Violin Plots for Valence&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">stat_summary</span><span class="p">(</span>
<span class="w">    </span><span class="n">fun</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mean</span><span class="p">,</span><span class="w"> </span><span class="n">colour</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;orange&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">geom</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;point&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="n">shape</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">18</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">5</span>
<span class="w">  </span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">theme</span><span class="p">(</span>
<span class="w">    </span><span class="n">plot.title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">element_text</span><span class="p">(</span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">31</span><span class="p">,</span><span class="w"> </span><span class="n">face</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;bold&quot;</span><span class="p">),</span>
<span class="w">    </span><span class="n">axis.text</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">element_text</span><span class="p">(</span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">21</span><span class="p">,</span><span class="w"> </span><span class="n">angle</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">10</span><span class="p">),</span>
<span class="w">    </span><span class="n">axis.title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">element_text</span><span class="p">(</span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">27</span><span class="p">),</span>
<span class="w">    </span><span class="n">legend.position</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;none&quot;</span>
<span class="w">  </span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">scale_fill_brewer</span><span class="p">(</span><span class="n">palette</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;BuPu&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">plot_grid</span><span class="p">(</span><span class="n">genre_danceability_side_boxplots</span><span class="p">,</span><span class="w"> </span><span class="n">genre_danceability_side_violin</span><span class="p">,</span><span class="w"> </span>
<span class="w">          </span><span class="n">genre_valence_side_boxplots</span><span class="p">,</span><span class="w"> </span><span class="n">genre_valence_side_violin</span><span class="p">,</span>
<span class="w">          </span><span class="n">nrow</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/bdcd1d52bd854990b3213b3fd578417b6056fc36e904c5ca2b99be906cadcd70.png" src="../_images/bdcd1d52bd854990b3213b3fd578417b6056fc36e904c5ca2b99be906cadcd70.png" />
</div>
</div>
<div class="exercise admonition" id="lecture2-q2">

<p class="admonition-title"><span class="caption-number">Exercise 5 </span></p>
<section id="exercise-content">
<p>What can we see <strong>descriptively</strong> from the above plots?</p>
</section>
</div>
</section>
<section id="data-modelling-framework">
<h3>3.4. Data Modelling Framework<a class="headerlink" href="#data-modelling-framework" title="Permalink to this heading">#</a></h3>
<p>A <strong>Multinomial Logistic Regression model</strong> is a suitable approach to our statistical inquiries given that <code class="docutils literal notranslate"><span class="pre">genre</span></code> is <strong>categorical</strong> and <strong>nominal</strong> (our response of interest) subject to the <strong>numerical</strong> regressors <code class="docutils literal notranslate"><span class="pre">danceability</span></code> and <code class="docutils literal notranslate"><span class="pre">valence</span></code>. Moreover, its corresponding regression estimates will allow us <strong>to measure variable association</strong>.</p>
<section id="primary-intuition-of-the-multinomial-logistic-regression-model">
<h4>3.4.1. Primary Intuition of the Multinomial Logistic Regression Model<a class="headerlink" href="#primary-intuition-of-the-multinomial-logistic-regression-model" title="Permalink to this heading">#</a></h4>
<p>Digging into the Multinomial Logistic regression model will require checking <strong>Binary Logistic regression</strong> first. Hence, let us do it quickly. Thus, suppose we are initially interested in two genres: <code class="docutils literal notranslate"><span class="pre">edm</span></code> and <code class="docutils literal notranslate"><span class="pre">latin</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">bin_spotify_training</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">spotify_training</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span>
<span class="w">  </span><span class="nf">filter</span><span class="p">(</span><span class="n">genre</span><span class="w"> </span><span class="o">%in%</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s">&quot;edm&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;latin&quot;</span><span class="p">))</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">  </span><span class="nf">mutate</span><span class="p">(</span><span class="n">genre</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">droplevels</span><span class="p">(</span><span class="n">genre</span><span class="p">))</span>
<span class="n">bin_spotify_training</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="dataframe">
<caption>A tibble: 87 × 6</caption>
<thead>
	<tr><th scope=col>title</th><th scope=col>artist</th><th scope=col>album_name</th><th scope=col>genre</th><th scope=col>danceability</th><th scope=col>valence</th></tr>
	<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>
</thead>
<tbody>
	<tr><td>Toda La Noche</td><td>Alok</td><td>Toda La Noche</td><td>latin</td><td>73.5</td><td>61.6</td></tr>
	<tr><td><span style=white-space:pre-wrap>On &amp; On      </span></td><td>Alok</td><td><span style=white-space:pre-wrap>On &amp; On      </span></td><td><span style=white-space:pre-wrap>edm  </span></td><td>74.7</td><td>67.0</td></tr>
	<tr><td>The Wall     </td><td>Alok</td><td>The Wall     </td><td>edm  </td><td>68.2</td><td>53.6</td></tr>
	<tr><td>Tell Me Why  </td><td>Alok</td><td>Tell Me Why  </td><td>edm  </td><td>56.1</td><td>19.5</td></tr>
	<tr><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td></tr>
	<tr><td>Renegades - Stash Konig Remix</td><td>X Ambassadors</td><td>Renegades (Stash Konig Remix)</td><td>edm</td><td>66.3</td><td>78.9</td></tr>
	<tr><td>Shake                        </td><td>Zeds Dead    </td><td>Shake                        </td><td>edm</td><td>50.1</td><td>36.6</td></tr>
	<tr><td>Sound Of The Underground     </td><td>Zeds Dead    </td><td>Sound Of The Underground     </td><td>edm</td><td>67.5</td><td>19.2</td></tr>
</tbody>
</table>
</div></div>
</div>
<p>Note <code class="docutils literal notranslate"><span class="pre">edm</span></code> is the baseline level (i.e., it appears on the left-hand side in the <code class="docutils literal notranslate"><span class="pre">levels()</span></code> output).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">levels</span><span class="p">(</span><span class="n">bin_spotify_training</span><span class="o">$</span><span class="n">genre</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>
.list-inline {list-style: none; margin:0; padding: 0}
.list-inline>li {display: inline-block}
.list-inline>li:not(:last-child)::after {content: "\00b7"; padding: 0 .5ex}
</style>
<ol class=list-inline><li>'edm'</li><li>'latin'</li></ol>
</div></div>
</div>
<p>Assuming we have a <strong>training set</strong> of <span class="math notranslate nohighlight">\(n\)</span> elements, recall that the <span class="math notranslate nohighlight">\(i\)</span>th response (for <span class="math notranslate nohighlight">\(i = 1, \dots, n\)</span>) in a <strong>Binary Logistic regression</strong> is</p>
<div class="math notranslate nohighlight">
\[\begin{split}Y_i =
\begin{cases}
1 \; \; \; \; \mbox{if the genre is } \texttt{latin},\\
0 \; \; \; \; \mbox{if the baseline genre is } \texttt{edm}.
\end{cases}
\end{split}\]</div>
<p>Therefore</p>
<div class="math notranslate nohighlight">
\[Y_i \sim \text{Bernoulli}(p_i),\]</div>
<p>whose probability of success is <span class="math notranslate nohighlight">\(p_i\)</span>.</p>
<p>In this model, we will use the following <strong>link function</strong> (where <span class="math notranslate nohighlight">\(X_{i,\texttt{dance}}\)</span> anf <span class="math notranslate nohighlight">\(X_{i,\texttt{val}}\)</span> are the <code class="docutils literal notranslate"><span class="pre">danceability</span></code> and <code class="docutils literal notranslate"><span class="pre">valence</span></code> scores for the <span class="math notranslate nohighlight">\(i\)</span>th song, respectively):</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
\mbox{logit}(p_i) &amp;= \log\left(\frac{p_i}{1 - p_i}\right) \nonumber \\
&amp;= \log \left[ \frac{P(Y_i = \texttt{latin}\mid X_{i,\texttt{dance}}, X_{i,\texttt{val}})}{P(Y_i = \texttt{edm} \mid X_{i,\texttt{dance}}, X_{i,\texttt{val}})}) \right] \nonumber \\
&amp;= \beta_0 + \beta_1 X_{i,\texttt{dance}} + \beta_2 X_{i,\texttt{val}}.
\end{align*}\end{split}\]</div>
<p>In plain words, the <strong>natural logarithm</strong> of the <strong>odds</strong> is equal to a <strong>systematic component</strong> containing the regressors <span class="math notranslate nohighlight">\(X_{i,\texttt{dance}}\)</span> and <span class="math notranslate nohighlight">\(X_{i,\texttt{val}}\)</span>.</p>
<p>Recall that this model can be fitted as follows:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">spotify_bin_log_model</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">glm</span><span class="p">(</span>
<span class="w">  </span><span class="n">formula</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">genre</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">danceability</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">valence</span><span class="p">,</span>
<span class="w">  </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">bin_spotify_training</span><span class="p">,</span>
<span class="w">  </span><span class="n">family</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">binomial</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Note that only <code class="docutils literal notranslate"><span class="pre">valence</span></code> is statistically significant for the response <code class="docutils literal notranslate"><span class="pre">genre</span></code> (<span class="math notranslate nohighlight">\(p\text{-value} &lt; .001\)</span>).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">tidy</span><span class="p">(</span><span class="n">spotify_bin_log_model</span><span class="p">,</span><span class="w"> </span><span class="n">conf.int</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">,</span><span class="w"> </span><span class="n">exponentiate</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="nf">mutate_if</span><span class="p">(</span><span class="n">is.numeric</span><span class="p">,</span><span class="w"> </span><span class="n">round</span><span class="p">,</span><span class="w"> </span><span class="m">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="dataframe">
<caption>A tibble: 3 × 7</caption>
<thead>
	<tr><th scope=col>term</th><th scope=col>estimate</th><th scope=col>std.error</th><th scope=col>statistic</th><th scope=col>p.value</th><th scope=col>conf.low</th><th scope=col>conf.high</th></tr>
	<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>
</thead>
<tbody>
	<tr><td>(Intercept) </td><td>0.36</td><td>1.70</td><td>-0.60</td><td>0.55</td><td>0.01</td><td>8.91</td></tr>
	<tr><td>danceability</td><td>0.97</td><td>0.03</td><td>-1.23</td><td>0.22</td><td>0.92</td><td>1.02</td></tr>
	<tr><td>valence     </td><td>1.05</td><td>0.01</td><td> 3.47</td><td>0.00</td><td>1.02</td><td>1.08</td></tr>
</tbody>
</table>
</div></div>
</div>
<p>Then, we make the corresponding coefficient interpretations (the previous output already provides the estimate on the odds scale via <code class="docutils literal notranslate"><span class="pre">exponentiate</span> <span class="pre">=</span> <span class="pre">TRUE</span></code>):</p>
<blockquote>
<div><p>For each unit increase in the <code class="docutils literal notranslate"><span class="pre">valence</span></code> score in the Spotify catalogue, the song is 1.05 times more likely to be <code class="docutils literal notranslate"><span class="pre">latin</span></code> than <code class="docutils literal notranslate"><span class="pre">edm</span></code>.</p>
</div></blockquote>
</section>
<section id="more-than-one-logit-function">
<h4>3.4.2.  More than One Logit Function<a class="headerlink" href="#more-than-one-logit-function" title="Permalink to this heading">#</a></h4>
<p><strong>What if our response is nominal and has more than two categories?</strong> In that case, let us suppose that a given <strong>discrete nominal response <span class="math notranslate nohighlight">\(Y_i\)</span> has categories <span class="math notranslate nohighlight">\(1, 2, \dots, m\)</span></strong>.</p>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>Categories <span class="math notranslate nohighlight">\(1, 2, \dots, m\)</span> <strong>are merely labels here</strong>. Thus, they <strong>do not</strong> implicate an ordinal scale.</p>
</div>
<p>This regression approach assumes a <a class="reference external" href="https://www.sciencedirect.com/topics/mathematics/multinomial-distribution"><strong>Multinomial distribution</strong></a> where <span class="math notranslate nohighlight">\(p_{i,1}, p_{i,2}, \dots, p_{i,m}\)</span> are the probabilities that <span class="math notranslate nohighlight">\(Y_i\)</span> will belong to categories <span class="math notranslate nohighlight">\(1, 2, \dots, m\)</span> respectively; i.e.,</p>
<div class="math notranslate nohighlight">
\[
P(Y_i = 1) = p_{i,1} \;\;\;\; P(Y_i = 2) = p_{i,2} \;\; \dots \;\; P(Y_i = m) = p_{i,m},
\]</div>
<p>where</p>
<div class="math notranslate nohighlight">
\[
\sum_{j = 1}^m p_{i,j} = p_{i,1} + p_{i,2} + \dots + p_{i,m} = 1.
\]</div>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>A particular highlight is that the Binomial distribution is the special Multinomial case when <span class="math notranslate nohighlight">\(m = 2\)</span>.</p>
</div>
<p>The Multinomial Logistic regression <strong>also models the logarithm of the odds</strong>. However, only one logarithm of the odds (or <strong>logit</strong>) will not be enough anymore. Recall we can capture the odds between two categories with a single logit function. <strong>What about adding some other ones?</strong></p>
<p>Here is what we can do:</p>
<ol class="arabic simple">
<li><p>Pick one of the categories to be the <strong>baseline</strong>. For example, the category “<span class="math notranslate nohighlight">\(1\)</span>”.</p></li>
<li><p>For each of the <strong>other</strong> categories, we model the logarithm of the odds to the baseline category.</p></li>
</ol>
<p>Now, <strong>what is the math for the general case with <span class="math notranslate nohighlight">\(m\)</span> response categories and <span class="math notranslate nohighlight">\(k\)</span> regressors?</strong> For the <span class="math notranslate nohighlight">\(i\)</span>th observation, we end up with a system of <span class="math notranslate nohighlight">\(m - 1\)</span> link functions in the Multinomial Logistic regression model as follows:</p>
<div class="math notranslate nohighlight" id="equation-multinomial-model">
<span class="eqno">(15)<a class="headerlink" href="#equation-multinomial-model" title="Permalink to this equation">#</a></span>\[\begin{split}\begin{gather*}
\eta_i^{(2,1)} = \log\left[\frac{P(Y_i = 2\mid X_{i,1}, \ldots, X_{i,k})}{P(Y_i = 1 \mid X_{i,1}, \ldots, X_{i,k})}\right] = \beta_0^{(2,1)} + \beta_1^{(2,1)} X_{i, 1} + \beta_2^{(2,1)} X_{i, 2} + \ldots + \beta_k^{(2,1)} X_{i, k} \\
\eta_i^{(3,1)} = \log\left[\frac{P(Y_i = 3\mid X_{i,1}, \ldots, X_{i,k})}{P(Y_i = 1 \mid X_{i,1}, \ldots, X_{i,k})}\right] = \beta_0^{(3,1)} + \beta_1^{(3,1)} X_{i, 1} + \beta_2^{(3,1)} X_{i, 2} + \ldots + \beta_k^{(3,1)} X_{i, k} \\
\vdots \\
\eta_i^{(m,1)} = \log\left[\frac{P(Y_i = m\mid X_{i,1}, \ldots, X_{i,k})}{P(Y_i = 1 \mid X_{i,1}, \ldots, X_{i,k})}\right] = \beta_0^{(m,1)} + \beta_1^{(m,1)} X_{i, 1} + \beta_2^{(m,1)} X_{i, 2} + \ldots + \beta_k^{(m,1)} X_{i, k}.
\end{gather*}\end{split}\]</div>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>Note that the superscript <span class="math notranslate nohighlight">\((j, 1)\)</span> in <a class="reference internal" href="#equation-multinomial-model">(15)</a> indicates that the equation is on level <span class="math notranslate nohighlight">\(j\)</span> (for <span class="math notranslate nohighlight">\(j = 2, \dots, m\)</span>) with respect to level <span class="math notranslate nohighlight">\(1\)</span>. Furthermore, <strong>the regression coefficients are different for each link function</strong>.</p>
</div>
<p>With some algebraic manipulation, we can show that the probabilities <span class="math notranslate nohighlight">\(p_{i,1}, p_{i,2}, \dots, p_{i,m}\)</span> of <span class="math notranslate nohighlight">\(Y_i\)</span> belonging to categories <span class="math notranslate nohighlight">\(1, 2, \dots, m\)</span> are:</p>
<div class="math notranslate nohighlight" id="equation-prob-multinomial">
<span class="eqno">(16)<a class="headerlink" href="#equation-prob-multinomial" title="Permalink to this equation">#</a></span>\[\begin{split}\begin{gather*}
p_{i,1} = P(Y_i = 1 \mid X_{i,1}, \ldots, X_{i,k}) = \frac{1}{1 + \sum_{j = 2}^m \exp \big( \eta_i^{(j,1)} \big)} \\
p_{i,2} = P(Y_i = 2 \mid X_{i,1}, \ldots, X_{i,k}) = \frac{\exp \big( \eta_i^{(2,1)} \big)}{1 + \sum_{j = 2}^m \exp \big( \eta_i^{(j,1)} \big)} \\
\vdots \\
p_{i,m} = P(Y_i = m \mid X_{i,1}, \ldots, X_{i,k}) = \frac{\exp \big( \eta_i^{(m,1)} \big)}{1 + \sum_{j = 2}^m \exp \big( \eta_i^{(j,1)} \big)}.
\end{gather*}\end{split}\]</div>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>If we sum all <span class="math notranslate nohighlight">\(m\)</span> probabilities in <a class="reference internal" href="#equation-prob-multinomial">(16)</a>, the sum will be equal to <span class="math notranslate nohighlight">\(1\)</span> for the <span class="math notranslate nohighlight">\(i\)</span>th observation. <strong>This is particularly important when we want to use this model for making predictions in classification matters</strong>.</p>
</div>
<p>Going back to our example, let us set the Multinomial Logistic regression model with <code class="docutils literal notranslate"><span class="pre">genre</span></code> as a response subject to <code class="docutils literal notranslate"><span class="pre">danceability</span></code> and <code class="docutils literal notranslate"><span class="pre">valence</span></code> as a continuous regressor. Level <code class="docutils literal notranslate"><span class="pre">edm</span></code> will be the baseline:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">levels</span><span class="p">(</span><span class="n">spotify_training</span><span class="o">$</span><span class="n">genre</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>
.list-inline {list-style: none; margin:0; padding: 0}
.list-inline>li {display: inline-block}
.list-inline>li:not(:last-child)::after {content: "\00b7"; padding: 0 .5ex}
</style>
<ol class=list-inline><li>'edm'</li><li>'latin'</li><li>'pop'</li><li>'r&amp;b'</li><li>'rap'</li><li>'rock'</li></ol>
</div></div>
</div>
<p>Specifically, this case will implicate a <strong>system of <span class="math notranslate nohighlight">\(m - 1 = 6 - 1= 5\)</span> regression equations</strong> (where <span class="math notranslate nohighlight">\(X_{i,\texttt{dance}}\)</span> anf <span class="math notranslate nohighlight">\(X_{i,\texttt{val}}\)</span> are the <code class="docutils literal notranslate"><span class="pre">danceability</span></code> and <code class="docutils literal notranslate"><span class="pre">valence</span></code> scores for the <span class="math notranslate nohighlight">\(i\)</span>th song, respectively):</p>
<div class="math notranslate nohighlight" id="equation-multinomial-model-spotify">
<span class="eqno">(17)<a class="headerlink" href="#equation-multinomial-model-spotify" title="Permalink to this equation">#</a></span>\[\begin{split}\begin{align*}
\eta_i^{(\texttt{latin},\texttt{edm})} = \log\left[\frac{P(Y_i = \texttt{latin} \mid X_{i, \texttt{dance}}, X_{i, \texttt{val}})}{P(Y_i = \texttt{edm} \mid X_{i, \texttt{dance}}, X_{i, \texttt{val}})}\right] = \beta_0^{(\texttt{latin},\texttt{edm})} + \beta_1^{(\texttt{latin},\texttt{edm})} X_{i, \texttt{dance}} + \beta_2^{(\texttt{latin},\texttt{edm})} X_{i, \texttt{val}} \\
\eta_i^{(\texttt{pop},\texttt{edm})} = \log\left[\frac{P(Y_i = \texttt{pop} \mid X_{i, \texttt{dance}}, X_{i, \texttt{val}})}{P(Y_i = \texttt{edm} \mid X_{i, \texttt{dance}}, X_{i, \texttt{val}})}\right] = \beta_0^{(\texttt{pop},\texttt{edm})} + \beta_1^{(\texttt{pop},\texttt{edm})} X_{i, \texttt{dance}} + \beta_2^{(\texttt{pop},\texttt{edm})} X_{i, \texttt{val}} \\
\eta_i^{(\texttt{r&amp;b},\texttt{edm})} = \log\left[\frac{P(Y_i = \texttt{r&amp;b} \mid X_{i, \texttt{dance}}, X_{i, \texttt{val}})}{P(Y_i = \texttt{edm} \mid X_{i, \texttt{dance}}, X_{i, \texttt{val}})}\right] = \beta_0^{(\texttt{r&amp;b},\texttt{edm})} + \beta_1^{(\texttt{r&amp;b},\texttt{edm})} X_{i, \texttt{dance}} + \beta_2^{(\texttt{r&amp;b},\texttt{edm})} X_{i, \texttt{val}} \\
\eta_i^{(\texttt{rap},\texttt{edm})} = \log\left[\frac{P(Y_i = \texttt{rap} \mid X_{i, \texttt{dance}}, X_{i, \texttt{val}})}{P(Y_i = \texttt{edm} \mid X_{i, \texttt{dance}}, X_{i, \texttt{val}})}\right] = \beta_0^{(\texttt{rap},\texttt{edm})} + \beta_1^{(\texttt{rap},\texttt{edm})} X_{i, \texttt{dance}} + \beta_2^{(\texttt{rap},\texttt{edm})} X_{i, \texttt{val}} \\
\eta_i^{(\texttt{rock},\texttt{edm})} = \log\left[\frac{P(Y_i = \texttt{rock} \mid X_{i, \texttt{dance}}, X_{i, \texttt{val}})}{P(Y_i = \texttt{edm} \mid X_{i, \texttt{dance}}, X_{i, \texttt{val}})}\right] = \beta_0^{(\texttt{rock},\texttt{edm})} + \beta_1^{(\texttt{rock},\texttt{edm})} X_{i, \texttt{dance}} + \beta_2^{(\texttt{rock},\texttt{edm})} X_{i, \texttt{val}}.
\end{align*}\end{split}\]</div>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>In a Multinomial Logistic regression model, each link function has its own intercept and regression coefficients.</p>
</div>
<p>The modelling system of 5 logit functions <a class="reference internal" href="#equation-multinomial-model-spotify">(17)</a> can also be mathematically represented as follows (which might be helpful for our subsequent coefficient interpretation:</p>
<div class="math notranslate nohighlight" id="equation-multinomial-model-spotify-2">
<span class="eqno">(18)<a class="headerlink" href="#equation-multinomial-model-spotify-2" title="Permalink to this equation">#</a></span>\[\begin{split}\begin{gather*}
\frac{P(Y_i = \texttt{latin}\mid X_{i,\texttt{dance}}, X_{i,\texttt{val}})}{P(Y_i = \texttt{edm} \mid X_{i,\texttt{dance}}, X_{i,\texttt{val}})} = \exp\left[\beta_0^{(\texttt{latin},\texttt{edm})}\right] \exp\left[\beta_1^{(\texttt{latin},\texttt{edm})} X_{i,\texttt{dance}}\right] \exp\left[\beta_2^{(\texttt{latin},\texttt{edm})} X_{i,\texttt{val}}\right] \\
\frac{P(Y_i = \texttt{pop}\mid X_{i,\texttt{dance}}, X_{i,\texttt{val}})}{P(Y_i = \texttt{edm} \mid X_{i,\texttt{dance}}, X_{i,\texttt{val}})} = \exp\left[\beta_0^{(\texttt{pop},\texttt{edm})}\right] \exp\left[\beta_1^{(\texttt{pop},\texttt{edm})} X_{i,\texttt{dance}}\right] \exp\left[\beta_2^{(\texttt{pop},\texttt{edm})} X_{i,\texttt{val}}\right] \\
\frac{P(Y_i = \texttt{r&amp;b}\mid X_{i,\texttt{dance}}, X_{i,\texttt{val}})}{P(Y_i = \texttt{edm} \mid X_{i,\texttt{dance}}, X_{i,\texttt{val}})} = \exp\left[\beta_0^{(\texttt{r&amp;b},\texttt{edm})}\right] \exp\left[\beta_1^{(\texttt{r&amp;b},\texttt{edm})} X_{i,\texttt{dance}}\right] \exp\left[\beta_2^{(\texttt{r&amp;b},\texttt{edm})} X_{i,\texttt{val}}\right]\\
\frac{P(Y_i = \texttt{rap}\mid X_{i,\texttt{dance}}, X_{i,\texttt{val}})}{P(Y_i = \texttt{edm} \mid X_{i,\texttt{dance}}, X_{i,\texttt{val}})} = \exp\left[\beta_0^{(\texttt{rap},\texttt{edm})}\right] \exp\left[\beta_1^{(\texttt{rap},\texttt{edm})} X_{i,\texttt{dance}}\right] \exp\left[\beta_2^{(\texttt{rap},\texttt{edm})} X_{i,\texttt{val}}\right]\\
\frac{P(Y_i = \texttt{rock}\mid X_{i,\texttt{dance}}, X_{i,\texttt{val}})}{P(Y_i = \texttt{edm} \mid X_{i,\texttt{dance}}, X_{i,\texttt{val}})} = \exp\left[\beta_0^{(\texttt{rock},\texttt{edm})}\right] \exp\left[\beta_1^{(\texttt{rock},\texttt{edm})} X_{i,\texttt{dance}}\right]
\exp\left[\beta_2^{(\texttt{rock},\texttt{edm})} X_{i,\texttt{val}}\right].
\end{gather*}\end{split}\]</div>
<p>Finally, the probabilities of <span class="math notranslate nohighlight">\(Y_i\)</span> belonging to categories <code class="docutils literal notranslate"><span class="pre">edm</span></code>, <code class="docutils literal notranslate"><span class="pre">latin</span></code>, <code class="docutils literal notranslate"><span class="pre">pop</span></code>, <code class="docutils literal notranslate"><span class="pre">r&amp;b</span></code>, <code class="docutils literal notranslate"><span class="pre">rap</span></code>, and <code class="docutils literal notranslate"><span class="pre">rock</span></code> are:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{gather*}
p_{i,\texttt{edm}} = P(Y_i = \texttt{edm} \mid X_{i,\texttt{dance}}, X_{i,\texttt{val}}) = \frac{1}{1 + \exp\big(\eta_i^{(\texttt{latin},\texttt{edm})}\big) + \exp\big(\eta_i^{(\texttt{pop},\texttt{edm})}\big) + \exp\big(\eta_i^{(\texttt{r&amp;b},\texttt{edm})}\big) + \exp\big(\eta_i^{(\texttt{rap},\texttt{edm})}\big) + \exp\big(\eta_i^{(\texttt{rock},\texttt{edm})}\big)} \\
p_{i,\texttt{latin}} = P(Y_i = \texttt{latin} \mid X_{i,\texttt{dance}}, X_{i,\texttt{val}}) = \frac{\exp\big(\eta_i^{(\texttt{latin},\texttt{edm})}\big)}{1 + \exp\big(\eta_i^{(\texttt{latin},\texttt{edm})}\big) + \exp\big(\eta_i^{(\texttt{pop},\texttt{edm})}\big) + \exp\big(\eta_i^{(\texttt{r&amp;b},\texttt{edm})}\big) + \exp\big(\eta_i^{(\texttt{rap},\texttt{edm})}\big) + \exp\big(\eta_i^{(\texttt{rock},\texttt{edm})}\big)}\\
p_{i,\texttt{pop}} = P(Y_i = \texttt{pop} \mid X_{i,\texttt{dance}}, X_{i,\texttt{val}}) = \frac{\exp\big(\eta_i^{(\texttt{pop},\texttt{edm})}\big)}{1 + \exp\big(\eta_i^{(\texttt{latin},\texttt{edm})}\big) + \exp\big(\eta_i^{(\texttt{pop},\texttt{edm})}\big) + \exp\big(\eta_i^{(\texttt{r&amp;b},\texttt{edm})}\big) + \exp\big(\eta_i^{(\texttt{rap},\texttt{edm})}\big) + \exp\big(\eta_i^{(\texttt{rock},\texttt{edm})}\big)} \\
p_{i,\texttt{r&amp;b}} = P(Y_i = \texttt{r&amp;b} \mid X_{i,\texttt{dance}}, X_{i,\texttt{val}}) = \frac{\exp\big(\eta_i^{(\texttt{r&amp;b},\texttt{edm})}\big)}{1 + \exp\big(\eta_i^{(\texttt{latin},\texttt{edm})}\big) + \exp\big(\eta_i^{(\texttt{pop},\texttt{edm})}\big) + \exp\big(\eta_i^{(\texttt{r&amp;b},\texttt{edm})}\big) + \exp\big(\eta_i^{(\texttt{rap},\texttt{edm})}\big) + \exp\big(\eta_i^{(\texttt{rock},\texttt{edm})}\big)} \\
p_{i,\texttt{rap}} = P(Y_i = \texttt{rap} \mid X_{i,\texttt{dance}}, X_{i,\texttt{val}}) = \frac{\exp\big(\eta_i^{(\texttt{rap},\texttt{edm})}\big)}{1 + \exp\big(\eta_i^{(\texttt{latin},\texttt{edm})}\big) + \exp\big(\eta_i^{(\texttt{pop},\texttt{edm})}\big) + \exp\big(\eta_i^{(\texttt{r&amp;b},\texttt{edm})}\big) + \exp\big(\eta_i^{(\texttt{rap},\texttt{edm})}\big) + \exp\big(\eta_i^{(\texttt{rock},\texttt{edm})}\big)} \\
p_{i,\texttt{rock}} = P(Y_i = \texttt{rock} \mid X_{i,\texttt{dance}}, X_{i,\texttt{val}}) = \frac{\exp\big(\eta_i^{(\texttt{rock},\texttt{edm})}\big)}{1 + \exp\big(\eta_i^{(\texttt{latin},\texttt{edm})}\big) + \exp\big(\eta_i^{(\texttt{pop},\texttt{edm})}\big) + \exp\big(\eta_i^{(\texttt{r&amp;b},\texttt{edm})}\big) + \exp\big(\eta_i^{(\texttt{rap},\texttt{edm})}\big) + \exp\big(\eta_i^{(\texttt{rock},\texttt{edm})}\big)}.
\end{gather*}\end{split}\]</div>
<p>Now, let us discuss some in-class questions:</p>
<div class="exercise admonition" id="lecture2-q3">

<p class="admonition-title"><span class="caption-number">Exercise 6 </span></p>
<section id="exercise-content">
<p>Answer <strong>TRUE</strong> or <strong>FALSE</strong>:</p>
<p>Now that we removed the restriction of only one link function, we also removed the distributional assumption for <span class="math notranslate nohighlight">\(Y_i\)</span>. Hence, our model has no distributional assumption.</p>
<p><strong>A.</strong> TRUE</p>
<p><strong>B.</strong> FALSE</p>
</section>
</div>
<div class="exercise admonition" id="lecture2-q4">

<p class="admonition-title"><span class="caption-number">Exercise 7 </span></p>
<section id="exercise-content">
<p>Answer <strong>TRUE</strong> or <strong>FALSE</strong>:</p>
<p>From the statistical point of view, the model is now non-parametric.</p>
<p><strong>A.</strong> TRUE</p>
<p><strong>B.</strong> FALSE</p>
</section>
</div>
<div class="exercise admonition" id="lecture2-q5">

<p class="admonition-title"><span class="caption-number">Exercise 8 </span></p>
<section id="exercise-content">
<p>Suppose that, given our inquiries, a peer suggests we fit two separate OLS with <code class="docutils literal notranslate"><span class="pre">genre</span></code> as a regressor and <code class="docutils literal notranslate"><span class="pre">danceability</span></code> <strong>OR</strong> <code class="docutils literal notranslate"><span class="pre">valence</span></code> as the responses. Can you think of some drawbacks of this suggested approach?</p>
</section>
</div>
</section>
</section>
<section id="id1">
<h3>3.5. Estimation<a class="headerlink" href="#id1" title="Permalink to this heading">#</a></h3>
<p><strong>All parameters</strong> in the Multinomial Logistic regression model are also unknown. To fit the model with the package <code class="docutils literal notranslate"><span class="pre">nnet</span></code>, we use the function <code class="docutils literal notranslate"><span class="pre">multinom()</span></code>, which obtains the corresponding estimates. The estimates are obtained through <strong>maximum likelihood</strong>, where we assume a <strong>Multinomial joint probability mass function</strong> of the <span class="math notranslate nohighlight">\(n\)</span> responses <span class="math notranslate nohighlight">\(Y_i\)</span>.</p>
<div class="warning admonition">
<p class="admonition-title">Note</p>
<p>We will not dig into mathematical derivations regarding MLE for this model since it would require digging into matrix notation, which is out of this course’s scope. That said, you can find more information on this matter <a class="reference external" href="https://czep.net/stat/mlelr.pdf"><strong>here</strong></a>.</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">spotify_mult_log_model</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">multinom</span><span class="p">(</span>
<span class="w">  </span><span class="n">formula</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">genre</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">danceability</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">valence</span><span class="p">,</span>
<span class="w">  </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">spotify_training</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span># weights:  24 (15 variable)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>initial  value 627.115814 
iter  10 value 582.728217
iter  20 value 559.441415
final  value 559.441352 
converged
</pre></div>
</div>
</div>
</div>
</section>
<section id="inference">
<h3>3.6. Inference<a class="headerlink" href="#inference" title="Permalink to this heading">#</a></h3>
<p><strong>We can determine whether a regressor is statistically associated with the logarithm of the odds</strong> through hypothesis testing for the parameters <span class="math notranslate nohighlight">\(\beta_j^{(u, v)}\)</span> <strong>by link function</strong>. We also use the <strong>Wald statistic</strong> <span class="math notranslate nohighlight">\(z_j^{(u, v)}\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{equation*}
z_j^{(u, v)} = \frac{\hat{\beta}_j^{(u, v)}}{\mbox{se}\left(\hat{\beta}_j^{(u, v)}\right)}
\end{equation*}\]</div>
<p>to test the hypotheses</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{gather*}
H_0: \beta_j^{(u, v)} = 0\\
H_a: \beta_j^{(u, v)} \neq 0.
\end{gather*}\end{split}\]</div>
<p>Provided the sample size <span class="math notranslate nohighlight">\(n\)</span> is large enough, <span class="math notranslate nohighlight">\(z_j\)</span> has an <strong>approximately Standard Normal distribution</strong> under <span class="math notranslate nohighlight">\(H_0\)</span>.</p>
<p><code class="docutils literal notranslate"><span class="pre">R</span></code> provides the corresponding <strong><span class="math notranslate nohighlight">\(p\)</span>-values</strong> for each <span class="math notranslate nohighlight">\(\beta_j^{(u, v)}\)</span>. The smaller the <span class="math notranslate nohighlight">\(p\)</span>-value, the stronger the evidence against the null hypothesis <span class="math notranslate nohighlight">\(H_0\)</span>. As in the previous regression models, we would set a predetermined significance level <span class="math notranslate nohighlight">\(\alpha\)</span> (usually taken to be 0.05) to infer if the <span class="math notranslate nohighlight">\(p\)</span>-value is small enough. If the <span class="math notranslate nohighlight">\(p\)</span>-value is smaller than the predetermined level <span class="math notranslate nohighlight">\(\alpha\)</span>, then you could claim that there is evidence to reject the null hypothesis. Hence, <span class="math notranslate nohighlight">\(p\)</span>-values that are small enough indicate that the data provides evidence in favour of <strong>association</strong> (<strong>or causation in the case of an experimental study!</strong>) between the response variable and the <span class="math notranslate nohighlight">\(j\)</span>th regressor.</p>
<p>Furthermore, given a specified level of confidence where <span class="math notranslate nohighlight">\(\alpha\)</span> is the significance level, we can construct approximate <span class="math notranslate nohighlight">\((1 - \alpha) \times 100\%\)</span> <strong>confidence intervals</strong> for the corresponding true value of <span class="math notranslate nohighlight">\(\beta_j^{(u, v)}\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{equation*}
\hat{\beta}_j^{(u, v)} \pm z_{\alpha/2}\mbox{se} \left( \hat{\beta}_j^{(u, v)} \right),
\end{equation*}\]</div>
<p>where <span class="math notranslate nohighlight">\(z_{\alpha/2}\)</span> is the upper <span class="math notranslate nohighlight">\(\alpha/2\)</span> quantile of the <strong>Standard Normal distribution</strong>.</p>
<p>We can also use the function <code class="docutils literal notranslate"><span class="pre">tidy()</span></code> from the <code class="docutils literal notranslate"><span class="pre">broom</span></code> package along with argument <code class="docutils literal notranslate"><span class="pre">conf.int</span> <span class="pre">=</span> <span class="pre">TRUE</span></code> to get the 95% confidence intervals <strong>by default</strong>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">options</span><span class="p">(</span><span class="n">repr.matrix.max.rows</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">15</span><span class="p">)</span>

<span class="n">mult_output</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">tidy</span><span class="p">(</span><span class="n">spotify_mult_log_model</span><span class="p">,</span>
<span class="w">  </span><span class="n">conf.int</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">,</span><span class="w"> </span><span class="n">exponentiate</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span>
<span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">  </span><span class="nf">mutate_if</span><span class="p">(</span><span class="n">is.numeric</span><span class="p">,</span><span class="w"> </span><span class="n">round</span><span class="p">,</span><span class="w"> </span><span class="m">3</span><span class="p">)</span>
<span class="n">mult_output</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="dataframe">
<caption>A tibble: 15 × 8</caption>
<thead>
	<tr><th scope=col>y.level</th><th scope=col>term</th><th scope=col>estimate</th><th scope=col>std.error</th><th scope=col>statistic</th><th scope=col>p.value</th><th scope=col>conf.low</th><th scope=col>conf.high</th></tr>
	<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>
</thead>
<tbody>
	<tr><td>latin</td><td>(Intercept) </td><td> 0.101</td><td>1.419</td><td>-1.617</td><td>0.106</td><td>0.006</td><td>  1.628</td></tr>
	<tr><td>latin</td><td>danceability</td><td> 0.981</td><td>0.020</td><td>-0.976</td><td>0.329</td><td>0.943</td><td>  1.020</td></tr>
	<tr><td>latin</td><td>valence     </td><td> 1.052</td><td>0.013</td><td> 4.007</td><td>0.000</td><td>1.026</td><td>  1.079</td></tr>
	<tr><td>pop  </td><td>(Intercept) </td><td> 2.492</td><td>0.893</td><td> 1.023</td><td>0.306</td><td>0.433</td><td> 14.337</td></tr>
	<tr><td>pop  </td><td>danceability</td><td> 0.985</td><td>0.013</td><td>-1.112</td><td>0.266</td><td>0.959</td><td>  1.011</td></tr>
	<tr><td>pop  </td><td>valence     </td><td> 1.006</td><td>0.009</td><td> 0.661</td><td>0.508</td><td>0.988</td><td>  1.024</td></tr>
	<tr><td><span style=white-space:pre-wrap>r&amp;b  </span></td><td>(Intercept) </td><td>14.547</td><td>0.811</td><td> 3.302</td><td>0.001</td><td>2.969</td><td> 71.274</td></tr>
	<tr><td><span style=white-space:pre-wrap>r&amp;b  </span></td><td>danceability</td><td> 0.963</td><td>0.013</td><td>-3.016</td><td>0.003</td><td>0.939</td><td><span style=white-space:pre-wrap>  0.987</span></td></tr>
	<tr><td><span style=white-space:pre-wrap>r&amp;b  </span></td><td><span style=white-space:pre-wrap>valence     </span></td><td> 1.008</td><td>0.008</td><td> 0.973</td><td>0.331</td><td>0.992</td><td><span style=white-space:pre-wrap>  1.025</span></td></tr>
	<tr><td>rap  </td><td>(Intercept) </td><td> 0.388</td><td>0.997</td><td>-0.949</td><td>0.342</td><td>0.055</td><td>  2.740</td></tr>
	<tr><td>rap  </td><td>danceability</td><td> 1.010</td><td>0.014</td><td> 0.704</td><td>0.482</td><td>0.982</td><td>  1.039</td></tr>
	<tr><td>rap  </td><td>valence     </td><td> 1.006</td><td>0.009</td><td> 0.611</td><td>0.541</td><td>0.988</td><td>  1.024</td></tr>
	<tr><td>rock </td><td>(Intercept) </td><td>27.651</td><td>1.037</td><td> 3.202</td><td>0.001</td><td>3.624</td><td>210.986</td></tr>
	<tr><td>rock </td><td>danceability</td><td> 0.918</td><td>0.019</td><td>-4.508</td><td>0.000</td><td>0.885</td><td>  0.953</td></tr>
	<tr><td>rock </td><td>valence     </td><td> 1.024</td><td>0.013</td><td> 1.930</td><td>0.054</td><td>1.000</td><td>  1.050</td></tr>
</tbody>
</table>
</div></div>
</div>
<p>The 15 exponentiated estimated regression parameters (via <code class="docutils literal notranslate"><span class="pre">exponentiate</span> <span class="pre">=</span> <span class="pre">TRUE</span></code> in <code class="docutils literal notranslate"><span class="pre">tidy()</span></code>) from the right-hand side of <a class="reference internal" href="#equation-multinomial-model-spotify-2">(18)</a> appear in the column <code class="docutils literal notranslate"><span class="pre">estimate.</span></code> Note that column <code class="docutils literal notranslate"><span class="pre">y.level</span></code> is related to the <strong>non-baseline</strong> level per function. Finally, to draw our inferential conclusions, let us filter those <span class="math notranslate nohighlight">\(p\)</span>-values less than <span class="math notranslate nohighlight">\(0.05\)</span> from <code class="docutils literal notranslate"><span class="pre">mult_output</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">mult_output</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">  </span><span class="n">dplyr</span><span class="o">::</span><span class="nf">filter</span><span class="p">(</span><span class="n">p.value</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="m">0.05</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="dataframe">
<caption>A tibble: 5 × 8</caption>
<thead>
	<tr><th scope=col>y.level</th><th scope=col>term</th><th scope=col>estimate</th><th scope=col>std.error</th><th scope=col>statistic</th><th scope=col>p.value</th><th scope=col>conf.low</th><th scope=col>conf.high</th></tr>
	<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>
</thead>
<tbody>
	<tr><td>latin</td><td>valence     </td><td> 1.052</td><td>0.013</td><td> 4.007</td><td>0.000</td><td>1.026</td><td>  1.079</td></tr>
	<tr><td><span style=white-space:pre-wrap>r&amp;b  </span></td><td>(Intercept) </td><td>14.547</td><td>0.811</td><td> 3.302</td><td>0.001</td><td>2.969</td><td> 71.274</td></tr>
	<tr><td><span style=white-space:pre-wrap>r&amp;b  </span></td><td>danceability</td><td> 0.963</td><td>0.013</td><td>-3.016</td><td>0.003</td><td>0.939</td><td><span style=white-space:pre-wrap>  0.987</span></td></tr>
	<tr><td>rock </td><td>(Intercept) </td><td>27.651</td><td>1.037</td><td> 3.202</td><td>0.001</td><td>3.624</td><td>210.986</td></tr>
	<tr><td>rock </td><td>danceability</td><td> 0.918</td><td>0.019</td><td>-4.508</td><td>0.000</td><td>0.885</td><td>  0.953</td></tr>
</tbody>
</table>
</div></div>
</div>
<p>Since our baseline response is <code class="docutils literal notranslate"><span class="pre">edm</span></code>, we can conclude the following with <span class="math notranslate nohighlight">\(\alpha = 0.05\)</span> <strong>on the Spotify platform</strong>:</p>
<ul class="simple">
<li><p>There is a statistical difference in <code class="docutils literal notranslate"><span class="pre">danceability</span></code> in <code class="docutils literal notranslate"><span class="pre">edm</span></code> versus <code class="docutils literal notranslate"><span class="pre">r&amp;b</span></code> and <code class="docutils literal notranslate"><span class="pre">rock</span></code>.</p></li>
<li><p>There is a statistical difference in <code class="docutils literal notranslate"><span class="pre">valence</span></code> in <code class="docutils literal notranslate"><span class="pre">edm</span></code> versus <code class="docutils literal notranslate"><span class="pre">latin</span></code>.</p></li>
</ul>
</section>
<section id="coefficient-interpretation">
<h3>3.7. Coefficient Interpretation<a class="headerlink" href="#coefficient-interpretation" title="Permalink to this heading">#</a></h3>
<p>Interpretation of the Multinomial Logistic regression coefficients is <strong>quite similar</strong> to the Binary Logistic regression. Let us interpret those significant regression coefficientes from column <code class="docutils literal notranslate"><span class="pre">estimate</span></code>:</p>
<blockquote>
<div><p><span class="math notranslate nohighlight">\(\beta_2^{(\texttt{latin},\texttt{edm})}\)</span>: for each unit increase in the <code class="docutils literal notranslate"><span class="pre">valence</span></code> score in the Spotify catalogue, the song is <span class="math notranslate nohighlight">\(1.052\)</span> times more likely to be <code class="docutils literal notranslate"><span class="pre">latin</span></code> than <code class="docutils literal notranslate"><span class="pre">edm</span></code>.</p>
</div></blockquote>
<blockquote>
<div><p><span class="math notranslate nohighlight">\(\beta_1^{(\texttt{r&amp;b},\texttt{edm})}\)</span>: for each unit increase in the <code class="docutils literal notranslate"><span class="pre">danceability</span></code> score in the Spotify catalogue, the odds for a song for being <code class="docutils literal notranslate"><span class="pre">r&amp;b</span></code> decrease by <span class="math notranslate nohighlight">\((1 - 0.963) \times 100\% = 3.7\%\)</span> compared to <code class="docutils literal notranslate"><span class="pre">edm</span></code>.</p>
</div></blockquote>
<blockquote>
<div><p><span class="math notranslate nohighlight">\(\beta_1^{(\texttt{ock},\texttt{edm})}\)</span>: for each unit increase in the <code class="docutils literal notranslate"><span class="pre">danceability</span></code> score in the Spotify catalogue, the odds for a song for being <code class="docutils literal notranslate"><span class="pre">rock</span></code> decrease by <span class="math notranslate nohighlight">\((1 - 0.918) \times 100\% = 8.2\%\)</span> compared to <code class="docutils literal notranslate"><span class="pre">edm</span></code>.</p>
</div></blockquote>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>If we want to use another <code class="docutils literal notranslate"><span class="pre">genre</span></code> as a baseline under this modelling approach, we would need to relevel our factor-type response and rerun the whole process.</p>
<p>Also, this example does not include categorical regressors. Nevertheless, interpreting their corresponding estimated regression coefficients is analogous to [<strong>Binary Logistic regression</strong>] using the baseline response level.</p>
</div>
</section>
<section id="predictions">
<h3>3.8. Predictions<a class="headerlink" href="#predictions" title="Permalink to this heading">#</a></h3>
<p>Suppose we want to predict the genre probabilities for a given song with a <code class="docutils literal notranslate"><span class="pre">danceability</span></code> score of <code class="docutils literal notranslate"><span class="pre">27.5</span></code> and <code class="docutils literal notranslate"><span class="pre">valence</span></code> of <code class="docutils literal notranslate"><span class="pre">30</span></code>. We could use the model <code class="docutils literal notranslate"><span class="pre">spotify_mult_log_model</span></code> for making such prediction as follows:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">pred_probs</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">round</span><span class="p">(</span><span class="nf">predict</span><span class="p">(</span><span class="n">spotify_mult_log_model</span><span class="p">,</span><span class="w"> </span><span class="nf">tibble</span><span class="p">(</span><span class="n">danceability</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">27.5</span><span class="p">,</span><span class="w"> </span><span class="n">valence</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">30</span><span class="p">),</span><span class="w"> </span><span class="n">type</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;probs&quot;</span><span class="p">),</span><span class="w"> </span><span class="m">2</span><span class="p">)</span>
<span class="n">pred_probs</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>
.dl-inline {width: auto; margin:0; padding: 0}
.dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}
.dl-inline>dt::after {content: ":\0020"; padding-right: .5ex}
.dl-inline>dt:not(:first-of-type) {padding-left: .5ex}
</style><dl class=dl-inline><dt>edm</dt><dd>0.06</dd><dt>latin</dt><dd>0.02</dd><dt>pop</dt><dd>0.12</dd><dt>r&amp;b</dt><dd>0.41</dd><dt>rap</dt><dd>0.04</dd><dt>rock</dt><dd>0.34</dd></dl>
</div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">sum</span><span class="p">(</span><span class="n">pred_probs</span><span class="p">)</span><span class="w"> </span><span class="c1"># Due to rounding, sum is 0.99 and not 1.</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">0.99</div></div>
</div>
<p>Note we have to use <code class="docutils literal notranslate"><span class="pre">type</span> <span class="pre">=</span> <span class="pre">&quot;probs&quot;</span></code> in the function <code class="docutils literal notranslate"><span class="pre">predict()</span></code> to obtain these predictions. Therefore, this given song has more chances of being <code class="docutils literal notranslate"><span class="pre">r&amp;b</span></code>.</p>
</section>
<section id="model-selection">
<h3>3.9. Model Selection<a class="headerlink" href="#model-selection" title="Permalink to this heading">#</a></h3>
<p><strong>To perform model selection</strong>, we can use the same techniques from the Binary Logistic regression model (check <a class="reference internal" href="appendix-binary-log-regression.html#bin-log-model-selection"><span class="std std-ref">8. Model Selection</span></a>). That said, some <code class="docutils literal notranslate"><span class="pre">R</span></code> coding functions might not be entirely available for the <code class="docutils literal notranslate"><span class="pre">multinom()</span></code> models. Still, these statistical techniques and metrics can be manually coded.</p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "r"
        },
        kernelOptions: {
            name: "ir",
            path: "./notes"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'ir'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="lecture1-glm-link-functions-and-count-regression.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Lecture 1 - Generalized Linear Models: Link Functions and Count Regression</p>
      </div>
    </a>
    <a class="right-next"
       href="lecture3_glm_ordinal_regression.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Lecture 3 - Generalized Linear Models: Ordinal Logistic Regression</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#today-s-learning-goals">Today’s Learning Goals</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#loading-libraries">Loading Libraries</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#likelihood-based-model-selection">1. Likelihood-based Model Selection</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-crabs-dataset">1.1. The Crabs Dataset</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#estimation">1.2. Estimation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#goodness-of-fit-test">1.3.  Goodness of Fit Test</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#a-note-on-the-null-deviance">A Note on the Null Deviance</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#analysis-of-deviance-for-nested-models">1.4. Analysis of Deviance for Nested Models</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#akaike-information-criterion">1.5. Akaike Information Criterion</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesian-information-criterion">1.6. Bayesian Information Criterion</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#categorical-type-responses">2. Categorical Type Responses</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#multinomial-logistic-regression">3. Multinomial Logistic Regression</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-spotify-dataset">3.1. The Spotify Dataset</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-wrangling-and-summary">3.2. Data Wrangling and Summary</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exploratory-data-analysis">3.3. Exploratory Data Analysis</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-modelling-framework">3.4. Data Modelling Framework</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#primary-intuition-of-the-multinomial-logistic-regression-model">3.4.1. Primary Intuition of the Multinomial Logistic Regression Model</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#more-than-one-logit-function">3.4.2.  More than One Logit Function</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">3.5. Estimation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#inference">3.6. Inference</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#coefficient-interpretation">3.7. Coefficient Interpretation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#predictions">3.8. Predictions</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#model-selection">3.9. Model Selection</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By G. Alexi Rodríguez-Arelis, Rodolfo Lourenzutti, and Vincenzo Coia
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>