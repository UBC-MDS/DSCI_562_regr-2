

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Binary Logistic Regression &#8212; DSCI 562 - Regression II</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/exercise.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'notes/appendix-binary-log-regression';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Regression Cheatsheet" href="appendix-reg-cheatsheet.html" />
    <link rel="prev" title="Lecture 8 - Missing Data" href="lecture8_missing_data.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../README.html">
  
  
  
  
    
    
      
    
    
    <img src="../_static/UBC_MDS_logo.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../_static/UBC_MDS_logo.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../README.html">
                    Welcome to DSCI 562: Regression II
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Lectures</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../lecture-learning-objectives.html">Lecture Learning Objectives</a></li>
<li class="toctree-l1"><a class="reference internal" href="lecture1-glm-link-functions-and-count-regression.html">Lecture 1 - Generalized Linear Models: Link Functions and Count Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="lecture2_glm_model_selection_multinomial.html">Lecture 2 - Generalized Linear Models: Model Selection and Multinomial Logistic Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="lecture3_glm_ordinal_regression.html">Lecture 3 - Generalized Linear Models: Ordinal Logistic Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="lecture4_linear_mixed_effects_models.html">Lecture 4 - Linear Mixed-Effects Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="lecture5_survival_analysis.html">Lecture 5 - Survival Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="lecture6_local_regression.html">Lecture 6 - Local Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="lecture7_quantile_regression.html">Lecture 7 - Quantile Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="lecture8_missing_data.html">Lecture 8 - Missing Data</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Appendices</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Binary Logistic Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="appendix-reg-cheatsheet.html">Regression Cheatsheet</a></li>
<li class="toctree-l1"><a class="reference internal" href="appendix-reg-mindmap.html">Regression Mind Map</a></li>
<li class="toctree-l1"><a class="reference internal" href="appendix-dist-cheatsheet.html">Distribution Cheatsheet</a></li>
<li class="toctree-l1"><a class="reference internal" href="appendix-greek-alphabet.html">Greek Alphabet</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">License and Code of Conduct</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../LICENSE.html">License</a></li>
<li class="toctree-l1"><a class="reference internal" href="../CODE-OF-CONDUCT.html">Code of Conduct</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.ubc.ca/MDS-2023-24/DSCI_562_regr-2_students" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.ubc.ca/MDS-2023-24/DSCI_562_regr-2_students/issues/new?title=Issue%20on%20page%20%2Fnotes/appendix-binary-log-regression.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/notes/appendix-binary-log-regression.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Binary Logistic Regression</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#loading-libraries">Loading Libraries</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-breast-cancer-dataset">1. The Breast Cancer Dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-modelling-framework">2. Data Modelling Framework</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#using-ordinary-least-squares-to-model-probabilities">2.1. Using Ordinary Least-Squares to Model Probabilities</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-logit-function">2.2. The Logit Function</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#general-modelling-framework">2.3. General Modelling Framework</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#estimation">3. Estimation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#inference">4. Inference</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#coefficient-interpretation">5. Coefficient Interpretation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#predictions">7. Predictions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-selection">8. Model Selection</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#analysis-of-deviance">8.1. Analysis of Deviance</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#akaike-information-criterion">8.2. Akaike Information Criterion</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesian-information-criterion">8.3. Bayesian Information Criterion</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#optional-9-model-diagnostics">(Optional) 9. Model Diagnostics</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#deviance-residuals">9.1. Deviance Residuals</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#binned-residual-plots">9.2. Binned Residual Plots</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="binary-logistic-regression">
<h1>Binary Logistic Regression<a class="headerlink" href="#binary-logistic-regression" title="Permalink to this heading">#</a></h1>
<p>We will review the model you saw in <strong>DSCI 561</strong> called <strong>Binary Logistic regression</strong>. From now on, we will use the term “<em>binary</em>” to differentiate it from further generalized linear models (GLMs) covered in this course. That said, it is essential to highlight that Binary Logistic regression is the most basic GLM.</p>
<p>Let us dig into this model by introducing an appropriate dataset.</p>
<section id="loading-libraries">
<h2>Loading Libraries<a class="headerlink" href="#loading-libraries" title="Permalink to this heading">#</a></h2>
<div class="cell tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">options</span><span class="p">(</span><span class="n">repr.plot.height</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">9</span><span class="p">,</span><span class="w"> </span><span class="n">repr.plot.width</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">20</span><span class="p">,</span><span class="w"> </span><span class="n">repr.matrix.max.rows</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">6</span><span class="p">)</span>
<span class="nf">source</span><span class="p">(</span><span class="s">&quot;../scripts/support_functions.R&quot;</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">tidyverse</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">mlbench</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">AER</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">cowplot</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">broom</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">performance</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">qqplotr</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="the-breast-cancer-dataset">
<h2>1. The Breast Cancer Dataset<a class="headerlink" href="#the-breast-cancer-dataset" title="Permalink to this heading">#</a></h2>
<p>The data frame <code class="docutils literal notranslate"><span class="pre">breast_cancer</span></code> is the Wisconsin Diagnostic Breast Cancer dataset (<a class="reference external" href="https://www.jstor.org/stable/171686">Mangasarian et al., 1995</a>). It has a <strong>binary</strong> response <code class="docutils literal notranslate"><span class="pre">target</span></code>: <strong>whether the tumour is <code class="docutils literal notranslate"><span class="pre">benign</span></code> or <code class="docutils literal notranslate"><span class="pre">malignant</span></code></strong>.</p>
<div class="admonition-the-breast-cancer-dataset admonition">
<p class="admonition-title">The Breast Cancer Dataset</p>
<p>This training dataset contains  569 observations from a digitized image of a fine needle aspirate (FNA) of a breast mass. The dataset details 30 real-valued characteristics (i.e., continuous regressors) plus the binary response and <code class="docutils literal notranslate"><span class="pre">ID</span></code> number. We will start working with the response <code class="docutils literal notranslate"><span class="pre">target</span></code> subject to the regressor <code class="docutils literal notranslate"><span class="pre">mean_radius</span></code>.</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">breast_cancer</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">suppressWarnings</span><span class="p">(</span><span class="nf">suppressMessages</span><span class="p">(</span><span class="nf">read_csv</span><span class="p">(</span><span class="s">&quot;../datasets/breast_cancer.csv&quot;</span><span class="p">)))</span>

<span class="n">breast_cancer_binary</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">breast_cancer</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">  </span><span class="n">dplyr</span><span class="o">::</span><span class="nf">select</span><span class="p">(</span><span class="n">mean_radius</span><span class="p">,</span><span class="w"> </span><span class="n">target</span><span class="p">)</span>
<span class="n">breast_cancer_binary</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="dataframe">
<caption>A tibble: 569 × 2</caption>
<thead>
	<tr><th scope=col>mean_radius</th><th scope=col>target</th></tr>
	<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th></tr>
</thead>
<tbody>
	<tr><td>17.99</td><td>malignant</td></tr>
	<tr><td>20.57</td><td>malignant</td></tr>
	<tr><td>19.69</td><td>malignant</td></tr>
	<tr><td>⋮</td><td>⋮</td></tr>
	<tr><td>16.60</td><td>malignant</td></tr>
	<tr><td>20.60</td><td>malignant</td></tr>
	<tr><td> 7.76</td><td>benign   </td></tr>
</tbody>
</table>
</div></div>
</div>
<div class="admonition-main-statistical-inquiries admonition">
<p class="admonition-title">Main Statistical Inquiries</p>
<p>Let us suppose we want to assess the following:</p>
<ul class="simple">
<li><p>Whether <code class="docutils literal notranslate"><span class="pre">target</span></code> and <code class="docutils literal notranslate"><span class="pre">mean_radius</span></code> are statistically associated and by how much.</p></li>
<li><p>Whether <code class="docutils literal notranslate"><span class="pre">target</span></code> and <code class="docutils literal notranslate"><span class="pre">mean_texture</span></code> are statistically associated and by how much.</p></li>
</ul>
</div>
</section>
<section id="data-modelling-framework">
<h2>2. Data Modelling Framework<a class="headerlink" href="#data-modelling-framework" title="Permalink to this heading">#</a></h2>
<p>We will set our binary response <span class="math notranslate nohighlight">\(Y_i\)</span> mathematically as:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
Y_i =
\begin{cases}
1 \; \; \; \; \mbox{if the $i$th tumour is malignant},\\
0 \; \; \; \; 	\mbox{otherwise.}
\end{cases}
\end{split}\]</div>
<p>The “1” category is referred as <strong>success</strong>.</p>
<p>Note each <span class="math notranslate nohighlight">\(Y_i\)</span> is a <strong>Bernoulli</strong> trial whose <strong>probability of success</strong> is <span class="math notranslate nohighlight">\(p_i\)</span>:</p>
<div class="math notranslate nohighlight">
\[Y_i \sim \text{Bernoulli}(p_i).\]</div>
<section id="using-ordinary-least-squares-to-model-probabilities">
<h3>2.1. Using Ordinary Least-Squares to Model Probabilities<a class="headerlink" href="#using-ordinary-least-squares-to-model-probabilities" title="Permalink to this heading">#</a></h3>
<p>We will take a “<em>naive</em>” approach to address our above main statistical inquiries. Suppose we use the “1” and “0” in the response as probabilities, and we estimate an ordinary least-squares (OLS) regression model to predict the mean of <span class="math notranslate nohighlight">\(Y_i\)</span> subject to <code class="docutils literal notranslate"><span class="pre">mean_radius</span></code>, <span class="math notranslate nohighlight">\(X_{\texttt{mr}_i}\)</span>:</p>
<div class="math notranslate nohighlight">
\[
\mathbb{E}(Y_i \mid X_{\texttt{mr}_i}) = p_i = \beta_0 + \beta_1 X_{\texttt{mr}_i}
\]</div>
<p>The code below transforms the response <code class="docutils literal notranslate"><span class="pre">target</span></code>, via <code class="docutils literal notranslate"><span class="pre">mutate()</span></code>, as a probability with two possible outcomes: <code class="docutils literal notranslate"><span class="pre">1</span></code> for <code class="docutils literal notranslate"><span class="pre">malignant</span></code> and <code class="docutils literal notranslate"><span class="pre">0</span></code> for <code class="docutils literal notranslate"><span class="pre">benign</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">breast_cancer_binary</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">breast_cancer_binary</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span>
<span class="w">  </span><span class="nf">mutate</span><span class="p">(</span><span class="n">target</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">if_else</span><span class="p">(</span><span class="n">target</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s">&quot;malignant&quot;</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="m">0</span><span class="p">))</span>
<span class="n">breast_cancer_binary</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="dataframe">
<caption>A tibble: 569 × 2</caption>
<thead>
	<tr><th scope=col>mean_radius</th><th scope=col>target</th></tr>
	<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>
</thead>
<tbody>
	<tr><td>17.99</td><td>1</td></tr>
	<tr><td>20.57</td><td>1</td></tr>
	<tr><td>19.69</td><td>1</td></tr>
	<tr><td>⋮</td><td>⋮</td></tr>
	<tr><td>16.60</td><td>1</td></tr>
	<tr><td>20.60</td><td>1</td></tr>
	<tr><td> 7.76</td><td>0</td></tr>
</tbody>
</table>
</div></div>
</div>
<p>Thus, the plot below shows two subsets of points located on two horizontal lines. Note that those tumours classified as malignant (<code class="docutils literal notranslate"><span class="pre">1</span></code> on the <span class="math notranslate nohighlight">\(y\)</span>-axis) tend to have a larger <code class="docutils literal notranslate"><span class="pre">mean_radius.</span></code></p>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>The OLS-fitted values of the 569 observations, with <code class="docutils literal notranslate"><span class="pre">mean_radius</span></code> as a regressor, are shown on the blue line. Recall that a probability cannot be negative or larger than <span class="math notranslate nohighlight">\(1\)</span>. Nonetheless, values larger than <span class="math notranslate nohighlight">\(20\)</span> for <code class="docutils literal notranslate"><span class="pre">mean_radius</span></code> generate predictions larger than <span class="math notranslate nohighlight">\(1\)</span>, which is absurd for a probability. Moreover, small values of <code class="docutils literal notranslate"><span class="pre">mean_radius</span></code> generate predictions of less than <span class="math notranslate nohighlight">\(0\)</span>, which again does not make sense!</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">breast_cancer_plot</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">breast_cancer_binary</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">  </span><span class="nf">ggplot</span><span class="p">()</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">geom_point</span><span class="p">(</span><span class="nf">aes</span><span class="p">(</span><span class="n">mean_radius</span><span class="p">,</span><span class="w"> </span><span class="n">target</span><span class="p">))</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">geom_smooth</span><span class="p">(</span><span class="nf">aes</span><span class="p">(</span><span class="n">mean_radius</span><span class="p">,</span><span class="w"> </span><span class="n">target</span><span class="p">),</span>
<span class="w">    </span><span class="n">method</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;lm&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">formula</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">se</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span>
<span class="w">  </span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">labs</span><span class="p">(</span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Prob. of a Malignant Tumour&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Mean Radius&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">ggtitle</span><span class="p">(</span><span class="s">&quot;OLS Fitted Regression Line&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">theme</span><span class="p">(</span>
<span class="w">    </span><span class="n">plot.title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">element_text</span><span class="p">(</span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">31</span><span class="p">,</span><span class="w"> </span><span class="n">face</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;bold&quot;</span><span class="p">),</span>
<span class="w">    </span><span class="n">axis.text</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">element_text</span><span class="p">(</span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">21</span><span class="p">),</span>
<span class="w">    </span><span class="n">axis.title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">element_text</span><span class="p">(</span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">27</span><span class="p">)</span>
<span class="w">  </span><span class="p">)</span><span class="w"> </span>
<span class="n">breast_cancer_plot</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/3fa60da4fdf3f4597a7edee42e6543b8e446f6f26381354e1757554fc1d135d4.png" src="../_images/3fa60da4fdf3f4597a7edee42e6543b8e446f6f26381354e1757554fc1d135d4.png" />
</div>
</div>
</section>
<section id="the-logit-function">
<h3>2.2. The Logit Function<a class="headerlink" href="#the-logit-function" title="Permalink to this heading">#</a></h3>
<p>Now, we might wonder:</p>
<blockquote>
<div><p>Is there a way to overcome the above out-of-range issue?</p>
</div></blockquote>
<p>Of course, there is a way involving a link function as explained in <a class="reference internal" href="lecture1-glm-link-functions-and-count-regression.html#link-function"><span class="std std-ref">4.9. Link Function</span></a>. Nonetheless, a simple logarithmic transformation will not save the day here since we have <span class="math notranslate nohighlight">\(Y_i\)</span> values equal to zero. Therefore, let us play around with the distribution theory from <a class="reference external" href="https://pages.github.ubc.ca/MDS-2023-24/DSCI_551_stat-prob-dsci_students/notes/appendix-dist-cheatsheet.html#bernoulli"><strong>DSCI 551</strong></a>. Recall these facts:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{gather*}
Y_i \sim \text{Bernoulli}(p_i) \\
\mathbb{E}(Y_i) = p_i.
\end{gather*}\end{split}\]</div>
<p>Given that the <strong>mean</strong> of a Bernoulli random variable <span class="math notranslate nohighlight">\(Y_i\)</span> is <span class="math notranslate nohighlight">\(p_i\)</span> under this modelling framework, we can establish the following link function (which is <a class="reference internal" href="lecture1-glm-link-functions-and-count-regression.html#link-function"><span class="std std-ref"><strong>monotonic and differentiable</strong></span></a>):</p>
<div class="math notranslate nohighlight" id="equation-eq-logit">
<span class="eqno">(22)<a class="headerlink" href="#equation-eq-logit" title="Permalink to this equation">#</a></span>\[
h(p_i) = \mbox{logit}(p_i)= \log\left(\frac{p_i}{1 - p_i}\right) = \beta_0 + \beta_1 X_{\texttt{mr}_i}.
\]</div>
<div class="tip admonition">
<p class="admonition-title">Definition of the Logit Function</p>
<p>The link function <a class="reference internal" href="#equation-eq-logit">(22)</a> is called the <strong>logarithm of the odds</strong> or <strong>logit function</strong>. This logit function <span class="math notranslate nohighlight">\(\log\left(\frac{p_i}{1 - p_i}\right)\)</span> covers the entire real line, which solves the out-of-range problem from OLS in this case.</p>
</div>
<p>As a link function, the logit function is <strong>monotonic</strong>. Hence, how can we transform back <span class="math notranslate nohighlight">\(h(p_i)\)</span> to the probability <span class="math notranslate nohighlight">\(p_i\)</span>? With some algebraic arrangements, we can come up with the following expression:</p>
<div class="math notranslate nohighlight">
\[
p_i = \frac{\exp \left( \beta_0 + \beta_1 X_{\texttt{mr}_i} \right) }{ \left[ 1 + \exp \left( \beta_0 + \beta_1 X_{\texttt{mr}_i} \right) \right] } \in [0,1].
\]</div>
<p>Note that this whole modelling framework via this link function is called <strong>Binary Logistic regression</strong>.</p>
<p>The plot below fits this <strong>simple</strong> (we only have one regressor!) Binary Logistic regression using <code class="docutils literal notranslate"><span class="pre">breast_cancer_binary</span></code> with <code class="docutils literal notranslate"><span class="pre">target</span></code> as a response and <code class="docutils literal notranslate"><span class="pre">mean_radius</span></code> as a regressor. We can do this via <code class="docutils literal notranslate"><span class="pre">geom_smooth()</span></code> using <code class="docutils literal notranslate"><span class="pre">method</span> <span class="pre">=</span> <span class="pre">&quot;glm&quot;</span></code> and <code class="docutils literal notranslate"><span class="pre">method.args</span> <span class="pre">=</span> <span class="pre">c(family</span> <span class="pre">=</span> <span class="pre">binomial)</span></code>.</p>
<p>Then, we obtain the <strong>in-sample predictions</strong></p>
<div class="math notranslate nohighlight">
\[\hat{p_i} = \frac{\exp \left( \hat{\beta}_0 + \hat{\beta}_1 x_{\texttt{mr}_i} \right) }{ \left[ 1 + \exp \left( \hat{\beta}_0 + \hat{\beta}_1 x_{\texttt{mr}_i} \right) \right] } \in [0,1].\]</div>
<p>and connect them as a red line. This red <span class="math notranslate nohighlight">\(S\)</span>-shaped function above is called the <strong>sigmoid function</strong>. Note this function covers all the real line of <code class="docutils literal notranslate"><span class="pre">mean_radius</span></code> but it is constrained between 0 and 1 for the probability of encountering a malignant tumour.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">breast_cancer_plot</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">breast_cancer_plot</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">geom_smooth</span><span class="p">(</span><span class="nf">aes</span><span class="p">(</span><span class="n">mean_radius</span><span class="p">,</span><span class="w"> </span><span class="n">target</span><span class="p">),</span>
<span class="w">    </span><span class="n">method</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;glm&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">formula</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">x</span><span class="p">,</span>
<span class="w">    </span><span class="n">method.args</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="n">family</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">binomial</span><span class="p">),</span><span class="w"> </span><span class="n">se</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;red&quot;</span>
<span class="w">  </span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">ggtitle</span><span class="p">(</span><span class="s">&quot;OLS (Blue) and Binary Logistic (Red) Fitted Regression Lines&quot;</span><span class="p">)</span>
<span class="n">breast_cancer_plot</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/78f37a643878d598754546b5f7e76195d0122c5e488fd8a2ec4a56dd57a3ffe3.png" src="../_images/78f37a643878d598754546b5f7e76195d0122c5e488fd8a2ec4a56dd57a3ffe3.png" />
</div>
</div>
</section>
<section id="general-modelling-framework">
<h3>2.3. General Modelling Framework<a class="headerlink" href="#general-modelling-framework" title="Permalink to this heading">#</a></h3>
<p>The Binary Logistic regression model has a response variable in the form:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
Y_i =
\begin{cases}
1 \; \; \; \; \mbox{if the $i$th observation is a success},\\
0 \; \; \; \; \mbox{otherwise.}
\end{cases}
\end{split}\]</div>
<p>As the response variable can only take the values <span class="math notranslate nohighlight">\(0\)</span> or <span class="math notranslate nohighlight">\(1\)</span>, the key parameter becomes the probability that <span class="math notranslate nohighlight">\(Y_i\)</span> takes on the value of <span class="math notranslate nohighlight">\(1\)</span>, i.e. the probability of success, denoted as <span class="math notranslate nohighlight">\(p_i\)</span>. Hence:</p>
<div class="math notranslate nohighlight">
\[
Y_i \sim \text{Bernoulli}(p_i).
\]</div>
<p>The Binary Logistic regression approach models the probability of success, <span class="math notranslate nohighlight">\(p_i\)</span>, of the binary response <span class="math notranslate nohighlight">\(Y_i\)</span>. To re-express <span class="math notranslate nohighlight">\(p_i\)</span> <strong>on an unrestricted scale</strong>, the modelling is done in terms of the logit function (the link function in this model).</p>
<p>Specifically, for a training set of size <span class="math notranslate nohighlight">\(n\)</span>, <span class="math notranslate nohighlight">\(p_i\)</span> (<span class="math notranslate nohighlight">\(i = 1, 2, \dots, n\)</span>) will depend on the values of the <span class="math notranslate nohighlight">\(k\)</span> regressors <span class="math notranslate nohighlight">\(X_{i, 1}, X_{i, 2}, \dots, X_{i, k}\)</span> in the form:</p>
<div class="math notranslate nohighlight">
\[
h(p_i) = \mbox{logit}(p_i) = \log \left( \frac{p_i}{1 - p_i} \right) = \beta_0 + \beta_1 X_{i, 1} + \beta_1 X_{i, 2} + \ldots + \beta_k X_{i, k},
\]</div>
<p>or equivalently</p>
<div class="math notranslate nohighlight">
\[
p_i = \frac{\exp \left[ \mbox{logit} (p_i) \right]}{1 + \exp \left[ \mbox{logit}(p_i) \right]}.
\]</div>
<p>Note that the <span class="math notranslate nohighlight">\(\log(\cdot)\)</span> notation in the model above refers to the <strong>natural logarithm</strong>, i.e., <strong>logarithm base <span class="math notranslate nohighlight">\(e\)</span></strong>. The equation above for <span class="math notranslate nohighlight">\(p_i\)</span> shows that this Binary Logistic regression model will result in values of the probability of success <span class="math notranslate nohighlight">\(p_i\)</span> that are always between 0 and 1.</p>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>The response in this GLM is called the log-odds, the logarithm of the odds</p>
<div class="math notranslate nohighlight">
\[\frac{p_i}{1 - p_i},\]</div>
<p>the ratio of the probability of the event to the probability of the non-event. For instance, if the event is that the tumour is malignant, the odds denote how likely the <span class="math notranslate nohighlight">\(i\)</span>th tumour is to be malignant compared to how unlikely it is. The coefficient <span class="math notranslate nohighlight">\(\beta_j\)</span> (<span class="math notranslate nohighlight">\(j = 1, \dots, k\)</span>) denotes how much the log-odds increases or decreases when the corresponding continuous regressor changes by one unit.</p>
</div>
</section>
</section>
<section id="estimation">
<h2>3. Estimation<a class="headerlink" href="#estimation" title="Permalink to this heading">#</a></h2>
<p>Under a general framework with <span class="math notranslate nohighlight">\(k\)</span> regressors, the <strong>regression parameters</strong> <span class="math notranslate nohighlight">\(\beta_0, \beta_1, \dots, \beta_k\)</span> in this model are also unknown. In order to fit the model, we can use the function <code class="docutils literal notranslate"><span class="pre">glm()</span></code> and its argument <code class="docutils literal notranslate"><span class="pre">family</span> <span class="pre">=</span> <span class="pre">binomial</span></code> (required to specify the binary nature of the response), which obtains the estimates <span class="math notranslate nohighlight">\(\hat{\beta}_0, \hat{\beta}_1, \dots, \hat{\beta}_k\)</span> (note the hat notation).</p>
<p>The estimates are obtained through <strong>maximum likelihood</strong> where we assume a <strong>joint probability mass function of the <span class="math notranslate nohighlight">\(n\)</span> responses <span class="math notranslate nohighlight">\(Y_i\)</span></strong>.</p>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>For the sake of coding clarity, you could also use <code class="docutils literal notranslate"><span class="pre">family</span> <span class="pre">=</span> <span class="pre">binomial(link</span> <span class="pre">=</span> <span class="pre">&quot;logit&quot;)</span></code>. Nevertheless, <code class="docutils literal notranslate"><span class="pre">link</span> <span class="pre">=</span> <span class="pre">&quot;logit&quot;</span></code> is a default in <code class="docutils literal notranslate"><span class="pre">glm()</span></code> for Binary Logistic regression. Thus, <code class="docutils literal notranslate"><span class="pre">family</span> <span class="pre">=</span> <span class="pre">binomial</span></code> suffices when using the logit function.</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">binary_log_model</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">glm</span><span class="p">(</span><span class="nf">as.factor</span><span class="p">(</span><span class="n">target</span><span class="p">)</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">mean_radius</span><span class="p">,</span>
<span class="w">  </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">breast_cancer_binary</span><span class="p">,</span><span class="w"> </span><span class="n">family</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">binomial</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="inference">
<h2>4. Inference<a class="headerlink" href="#inference" title="Permalink to this heading">#</a></h2>
<p>We can determine <strong>whether a regressor is statistically associated with the logarithm of the response’s odds</strong> through <strong>hypothesis testing</strong> for the parameters <span class="math notranslate nohighlight">\(\beta_j\)</span>. We will need information about the estimated regression coefficient <span class="math notranslate nohighlight">\(\hat{\beta}_j\)</span> and its corresponding variability which is reflected in the <strong>standard error</strong> of the estimate, <span class="math notranslate nohighlight">\(\mbox{se} \left( \hat{\beta}_j \right)\)</span>.</p>
<p>To determine the <strong>statistical significance</strong> of <span class="math notranslate nohighlight">\(\hat{\beta}_j\)</span>, you can use the <strong>Wald statistic</strong></p>
<div class="math notranslate nohighlight">
\[
z_j = \frac{\hat{\beta}_j}{\mbox{se} \left( \hat{\beta}_j \right)}
\]</div>
<p>to test the hypotheses</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{gather*}
H_0: \beta_j = 0 \\
H_a: \beta_j \neq 0.
\end{gather*}\end{split}\]</div>
<p><strong>A statistic like <span class="math notranslate nohighlight">\(z_j\)</span> is analogous to the <span class="math notranslate nohighlight">\(t\)</span>-value in OLS regression.</strong> However, in Binary Logistic regression, provided the sample size <span class="math notranslate nohighlight">\(n\)</span> is large enough, <span class="math notranslate nohighlight">\(z_j\)</span> has an <strong>approximately Standard Normal distribution</strong> under <span class="math notranslate nohighlight">\(H_0\)</span> rather than a <span class="math notranslate nohighlight">\(t\)</span>-distribution.</p>
<p><code class="docutils literal notranslate"><span class="pre">R</span></code> provides the corresponding <strong><span class="math notranslate nohighlight">\(p\)</span>-value</strong> for each <span class="math notranslate nohighlight">\(\beta_j\)</span>. The smaller the <span class="math notranslate nohighlight">\(p\)</span>-value, the stronger the evidence against the null hypothesis <span class="math notranslate nohighlight">\(H_0\)</span>. Hence, a small enough <span class="math notranslate nohighlight">\(p\)</span>-value (less than the significance level <span class="math notranslate nohighlight">\(\alpha\)</span>) indicates that the data provides evidence in favour of <strong>association</strong> (<strong>or causation in the case of an experimental study!</strong>) between the log-dds and the <span class="math notranslate nohighlight">\(j\)</span>th regressor. Furthermore, given a specified level of confidence, we can construct approximate <span class="math notranslate nohighlight">\((1 - \alpha) \times 100\%\)</span> <strong>confidence intervals</strong> (CIs) for the corresponding true value of <span class="math notranslate nohighlight">\(\beta_j\)</span>:</p>
<div class="math notranslate nohighlight">
\[
\hat{\beta}_j \pm z_{\alpha/2}\mbox{se} \left( \hat{\beta}_j \right),
\]</div>
<p>where <span class="math notranslate nohighlight">\(z_{\alpha/2}\)</span> is the upper <span class="math notranslate nohighlight">\(\alpha/2\)</span> quantile of the <strong>Standard Normal distribution</strong>.</p>
<p>Now, we can answer the following:</p>
<blockquote>
<div><p>Is <code class="docutils literal notranslate"><span class="pre">mean_radius</span></code> statistically associated with the logarithm of the odds of <code class="docutils literal notranslate"><span class="pre">target</span></code>?</p>
</div></blockquote>
<p>We can also use the function <code class="docutils literal notranslate"><span class="pre">tidy()</span></code> from the <code class="docutils literal notranslate"><span class="pre">broom</span></code> package along with argument <code class="docutils literal notranslate"><span class="pre">conf.int</span> <span class="pre">=</span> <span class="pre">TRUE</span></code> to get the 95% confidence intervals <strong>by default</strong>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">tidy</span><span class="p">(</span><span class="n">binary_log_model</span><span class="p">,</span><span class="w"> </span><span class="n">conf.int</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="nf">mutate_if</span><span class="p">(</span><span class="n">is.numeric</span><span class="p">,</span><span class="w"> </span><span class="n">round</span><span class="p">,</span><span class="w"> </span><span class="m">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="dataframe">
<caption>A tibble: 2 × 7</caption>
<thead>
	<tr><th scope=col>term</th><th scope=col>estimate</th><th scope=col>std.error</th><th scope=col>statistic</th><th scope=col>p.value</th><th scope=col>conf.low</th><th scope=col>conf.high</th></tr>
	<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>
</thead>
<tbody>
	<tr><td>(Intercept)</td><td>-15.246</td><td>1.325</td><td>-11.510</td><td>0</td><td>-18.034</td><td>-12.826</td></tr>
	<tr><td>mean_radius</td><td>  1.034</td><td>0.093</td><td> 11.101</td><td>0</td><td>  0.864</td><td>  1.230</td></tr>
</tbody>
</table>
</div></div>
</div>
<p>Our sample gives us evidence to reject <span class="math notranslate nohighlight">\(H_0\)</span> (<span class="math notranslate nohighlight">\(p\text{-value} &lt; .001\)</span>). So <code class="docutils literal notranslate"><span class="pre">mean_radius</span></code> is statistically associated to the logarithm of the odds of <code class="docutils literal notranslate"><span class="pre">target</span></code>.</p>
</section>
<section id="coefficient-interpretation">
<h2>5. Coefficient Interpretation<a class="headerlink" href="#coefficient-interpretation" title="Permalink to this heading">#</a></h2>
<blockquote>
<div><p>What is the interpretation of the estimate <span class="math notranslate nohighlight">\(\hat{\beta}_1\)</span> for <code class="docutils literal notranslate"><span class="pre">mean_radius</span></code> on the response <code class="docutils literal notranslate"><span class="pre">target</span></code>?</p>
</div></blockquote>
<p>We have to transform back our estimated coefficient <span class="math notranslate nohighlight">\(\hat{\beta_1}\)</span> to the original scale of the odds <span class="math notranslate nohighlight">\(\frac{p_i}{1 - p_i}\)</span>. Function <code class="docutils literal notranslate"><span class="pre">tidy()</span></code> has the handy argument <code class="docutils literal notranslate"><span class="pre">exponentiate</span> <span class="pre">=</span> <span class="pre">TRUE</span></code> which exponentiates the <code class="docutils literal notranslate"><span class="pre">estimate</span></code> column along with the CIs (note the rest of the columns remain untransformed).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">tidy</span><span class="p">(</span><span class="n">binary_log_model</span><span class="p">,</span><span class="w"> </span><span class="n">conf.int</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">,</span><span class="w"> </span><span class="n">exponentiate</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="nf">mutate_if</span><span class="p">(</span><span class="n">is.numeric</span><span class="p">,</span><span class="w"> </span><span class="n">round</span><span class="p">,</span><span class="w"> </span><span class="m">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="dataframe">
<caption>A tibble: 2 × 7</caption>
<thead>
	<tr><th scope=col>term</th><th scope=col>estimate</th><th scope=col>std.error</th><th scope=col>statistic</th><th scope=col>p.value</th><th scope=col>conf.low</th><th scope=col>conf.high</th></tr>
	<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>
</thead>
<tbody>
	<tr><td>(Intercept)</td><td>0.00</td><td>1.32</td><td>-11.51</td><td>0</td><td>0.00</td><td>0.00</td></tr>
	<tr><td>mean_radius</td><td>2.81</td><td>0.09</td><td> 11.10</td><td>0</td><td>2.37</td><td>3.42</td></tr>
</tbody>
</table>
</div></div>
</div>
<p>The interpretation is:</p>
<blockquote>
<div><p>For each unit increase in <code class="docutils literal notranslate"><span class="pre">mean_radius</span></code>, the tumour is 2.81 times more likely to be malignant than to be benign.</p>
</div></blockquote>
<p>This example does not provide interpretations for <strong>categorical explanatory variables</strong>. That said, as in OLS multiple regression, the model would estimate multiple regression coefficients for that categorical explanatory variable: one for each level other than the <strong>baseline level</strong>. The interpretation of each estimated regression coefficient will depend on which category is specified as the baseline category.</p>
<p>Recall <a class="reference internal" href="lecture1-glm-link-functions-and-count-regression.html#dummy-var"><span class="std std-numref">Table 1</span></a>, which describes dummy variables for a nominal explanatory variable with <span class="math notranslate nohighlight">\(u\)</span> categories, where <strong>Level 1</strong> was specified as the baseline level, so all <span class="math notranslate nohighlight">\(u - 1\)</span> dummy variables are zero for that level. The estimated regression coefficient for <strong>Level 2</strong> represents how much the log-odds increases or decreases compared to the baseline category. The same interpretation applies to the regression coefficients for levels <span class="math notranslate nohighlight">\(3, \dots, u\)</span>. If we want to interpret these coefficients on the original scale of the odds <span class="math notranslate nohighlight">\(\frac{p_i}{1 - p_i}\)</span>, then we exponentiate each one of these estimated coefficients.</p>
<p>Now, let us fit a second model with two regressors: <code class="docutils literal notranslate"><span class="pre">mean_radius</span></code> (<span class="math notranslate nohighlight">\(X_{\texttt{mr}_i}\)</span>) and <code class="docutils literal notranslate"><span class="pre">mean_texture</span></code> (<span class="math notranslate nohighlight">\(X_{\texttt{mt}_i}\)</span>) for the <span class="math notranslate nohighlight">\(i\)</span>th observation:</p>
<div class="math notranslate nohighlight">
\[
\eta_i = \mbox{logit}(p_i)= \log\left(\frac{p_i}{1 - p_i}\right) = \beta_0 + \beta_1 X_{\texttt{mr}_i} + \beta_2 X_{\texttt{mt}_i}.
\]</div>
<p>Firstly, we select the necessary columns from our dataset <code class="docutils literal notranslate"><span class="pre">breast_cancer</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">breast_cancer_binary_2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">breast_cancer</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">  </span><span class="n">dplyr</span><span class="o">::</span><span class="nf">select</span><span class="p">(</span><span class="n">mean_radius</span><span class="p">,</span><span class="w"> </span><span class="n">mean_texture</span><span class="p">,</span><span class="w"> </span><span class="n">target</span><span class="p">)</span>
<span class="n">breast_cancer_binary_2</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="dataframe">
<caption>A tibble: 569 × 3</caption>
<thead>
	<tr><th scope=col>mean_radius</th><th scope=col>mean_texture</th><th scope=col>target</th></tr>
	<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th></tr>
</thead>
<tbody>
	<tr><td>17.99</td><td>10.38</td><td>malignant</td></tr>
	<tr><td>20.57</td><td>17.77</td><td>malignant</td></tr>
	<tr><td>19.69</td><td>21.25</td><td>malignant</td></tr>
	<tr><td>⋮</td><td>⋮</td><td>⋮</td></tr>
	<tr><td>16.60</td><td>28.08</td><td>malignant</td></tr>
	<tr><td>20.60</td><td>29.33</td><td>malignant</td></tr>
	<tr><td> 7.76</td><td>24.54</td><td>benign   </td></tr>
</tbody>
</table>
</div></div>
</div>
<p>Then, we fit the corresponding Binary Logistic regression.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">binary_log_model_2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">glm</span><span class="p">(</span><span class="nf">as.factor</span><span class="p">(</span><span class="n">target</span><span class="p">)</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">mean_radius</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">mean_texture</span><span class="p">,</span>
<span class="w">  </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">breast_cancer_binary_2</span><span class="p">,</span><span class="w"> </span><span class="n">family</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">binomial</span><span class="p">)</span>
<span class="nf">tidy</span><span class="p">(</span><span class="n">binary_log_model_2</span><span class="p">,</span><span class="w"> </span><span class="n">conf.int</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="nf">mutate_if</span><span class="p">(</span><span class="n">is.numeric</span><span class="p">,</span><span class="w"> </span><span class="n">round</span><span class="p">,</span><span class="w"> </span><span class="m">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="dataframe">
<caption>A tibble: 3 × 7</caption>
<thead>
	<tr><th scope=col>term</th><th scope=col>estimate</th><th scope=col>std.error</th><th scope=col>statistic</th><th scope=col>p.value</th><th scope=col>conf.low</th><th scope=col>conf.high</th></tr>
	<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>
</thead>
<tbody>
	<tr><td>(Intercept) </td><td>-19.849</td><td>1.774</td><td>-11.189</td><td>0</td><td>-23.592</td><td>-16.615</td></tr>
	<tr><td>mean_radius </td><td>  1.057</td><td>0.101</td><td> 10.417</td><td>0</td><td>  0.872</td><td>  1.271</td></tr>
	<tr><td>mean_texture</td><td>  0.218</td><td>0.037</td><td>  5.885</td><td>0</td><td>  0.147</td><td>  0.293</td></tr>
</tbody>
</table>
</div></div>
</div>
<p>Note that both regressors (<code class="docutils literal notranslate"><span class="pre">mean_radius</span></code> and <code class="docutils literal notranslate"><span class="pre">mean_texture</span></code>) are statistically significant for the response <code class="docutils literal notranslate"><span class="pre">target</span></code> (<span class="math notranslate nohighlight">\(p\text{-values} &lt; .001\)</span>). Then, we make the corresponding coefficient interpretations:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">tidy</span><span class="p">(</span><span class="n">binary_log_model_2</span><span class="p">,</span><span class="w"> </span><span class="n">conf.int</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">,</span><span class="w"> </span><span class="n">exponentiate</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="nf">mutate_if</span><span class="p">(</span><span class="n">is.numeric</span><span class="p">,</span><span class="w"> </span><span class="n">round</span><span class="p">,</span><span class="w"> </span><span class="m">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="dataframe">
<caption>A tibble: 3 × 7</caption>
<thead>
	<tr><th scope=col>term</th><th scope=col>estimate</th><th scope=col>std.error</th><th scope=col>statistic</th><th scope=col>p.value</th><th scope=col>conf.low</th><th scope=col>conf.high</th></tr>
	<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>
</thead>
<tbody>
	<tr><td>(Intercept) </td><td>0.00</td><td>1.77</td><td>-11.19</td><td>0</td><td>0.00</td><td>0.00</td></tr>
	<tr><td>mean_radius </td><td>2.88</td><td>0.10</td><td> 10.42</td><td>0</td><td>2.39</td><td>3.57</td></tr>
	<tr><td>mean_texture</td><td>1.24</td><td>0.04</td><td>  5.89</td><td>0</td><td>1.16</td><td>1.34</td></tr>
</tbody>
</table>
</div></div>
</div>
<p>The interpretation for <code class="docutils literal notranslate"><span class="pre">mean_radius</span></code> is:</p>
<blockquote>
<div><p>For each unit increase in <code class="docutils literal notranslate"><span class="pre">mean_radius</span></code>, the tumour is 2.88 times more likely to be malignant than to be benign while holding <code class="docutils literal notranslate"><span class="pre">mean_texture</span></code> constant.</p>
</div></blockquote>
<p>The interpretation for <code class="docutils literal notranslate"><span class="pre">mean_texture</span></code> is:</p>
<blockquote>
<div><p>For each unit increase in <code class="docutils literal notranslate"><span class="pre">mean_texture</span></code>, the tumour is 1.24 times more likely to be malignant than to be benign while holding <code class="docutils literal notranslate"><span class="pre">mean_radius</span></code> constant.”</p>
</div></blockquote>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>Note that the estimated coefficients for each regressor are standalone. Hence, we have to clarify that each estimate stands while holding the other regressor constant. This same interpretation holds with more than two regressors.</p>
</div>
</section>
<section id="predictions">
<h2>7. Predictions<a class="headerlink" href="#predictions" title="Permalink to this heading">#</a></h2>
<p>Suppose we want to predict the odds of a tumour being malignant to being benign using our trained <code class="docutils literal notranslate"><span class="pre">binary_log_model_2</span></code>. This tumour has the following values for <code class="docutils literal notranslate"><span class="pre">mean_radius</span></code> and <code class="docutils literal notranslate"><span class="pre">mean_texture</span></code>: <span class="math notranslate nohighlight">\(x_{\texttt{mr}} = 16\)</span> and <span class="math notranslate nohighlight">\( x_{\texttt{mt}} = 20\)</span>, respectively.</p>
<p>We use <code class="docutils literal notranslate"><span class="pre">binary_log_model_2</span></code> for making such prediction as follows:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{gather*} 
\log \left( \frac{\hat{p}}{1 - \hat{p}} \right) = \underbrace{-19.849}_{\hat{\beta}_0} + \underbrace{1.057}_{\hat{\beta}_1}(16) + \underbrace{0.218}_{\hat{\beta}_2}(20) = 1.43 \\
\frac{\hat{p}}{1 - \hat{p}} = 4.17.
\end{gather*}\end{split}\]</div>
<p>We can use the function <code class="docutils literal notranslate"><span class="pre">predict()</span></code> via the argument <code class="docutils literal notranslate"><span class="pre">type</span> <span class="pre">=</span> <span class="pre">&quot;link&quot;</span></code> to obtain the predicted logarithm of the odds. Then, we exponentiate it to get the predicted odds.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">round</span><span class="p">(</span><span class="nf">exp</span><span class="p">(</span><span class="nf">predict</span><span class="p">(</span><span class="n">binary_log_model_2</span><span class="p">,</span>
<span class="w">  </span><span class="nf">tibble</span><span class="p">(</span><span class="n">mean_radius</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">16</span><span class="p">,</span><span class="w"> </span><span class="n">mean_texture</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">20</span><span class="p">),</span>
<span class="w">  </span><span class="n">type</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;link&quot;</span>
<span class="p">)),</span><span class="w"> </span><span class="m">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><strong>1:</strong> 4.17</div></div>
</div>
<p>Hence, a tumour with <span class="math notranslate nohighlight">\(x_{\texttt{mr}} = 16\)</span> and <span class="math notranslate nohighlight">\( x_{\texttt{mt}} = 20\)</span> is predicted to be 4.17 times more likely to be malignant than benign.</p>
<p><strong>Can We Predict Probabilities For Classification Purposes?</strong></p>
<p>Using the function <code class="docutils literal notranslate"><span class="pre">predict()</span></code> via the argument <code class="docutils literal notranslate"><span class="pre">type</span> <span class="pre">=</span> <span class="pre">&quot;response&quot;</span></code> with the object <code class="docutils literal notranslate"><span class="pre">binary_log_model_2</span></code>, we can obtain the estimated probability for a tumour to be malignant with the following values for <code class="docutils literal notranslate"><span class="pre">mean_radius</span></code> and <code class="docutils literal notranslate"><span class="pre">mean_texture</span></code>: <span class="math notranslate nohighlight">\(x_{\texttt{mr}} = 16\)</span> and <span class="math notranslate nohighlight">\( x_{\texttt{mt}} = 20\)</span> respectively.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">round</span><span class="p">(</span><span class="nf">predict</span><span class="p">(</span><span class="n">binary_log_model_2</span><span class="p">,</span>
<span class="w">  </span><span class="nf">tibble</span><span class="p">(</span><span class="n">mean_radius</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">16</span><span class="p">,</span><span class="w"> </span><span class="n">mean_texture</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">20</span><span class="p">),</span>
<span class="w">  </span><span class="n">type</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;response&quot;</span>
<span class="p">),</span><span class="w"> </span><span class="m">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><strong>1:</strong> 0.81</div></div>
</div>
<p>Hence, a tumour with <span class="math notranslate nohighlight">\(x_{\texttt{mr}} = 16\)</span> and <span class="math notranslate nohighlight">\( x_{\texttt{mt}} = 20\)</span> has a predicted probability of 0.81 of beign malignant.</p>
</section>
<section id="model-selection">
<span id="bin-log-model-selection"></span><h2>8. Model Selection<a class="headerlink" href="#model-selection" title="Permalink to this heading">#</a></h2>
<p><strong>To perform model selection</strong>, let us recall our two Binary Logistic regression models with <code class="docutils literal notranslate"><span class="pre">target</span></code> as a response. <strong>Model 1</strong> will only have the continuous <code class="docutils literal notranslate"><span class="pre">mean_radius</span></code> (<span class="math notranslate nohighlight">\(X_{\texttt{mr}_i}\)</span>) as a regressor (i.e., <code class="docutils literal notranslate"><span class="pre">binary_log_model</span></code>), whereas <strong>Model 2</strong> will have <code class="docutils literal notranslate"><span class="pre">mean_radius</span></code> and <code class="docutils literal notranslate"><span class="pre">mean_texture</span></code> (<span class="math notranslate nohighlight">\(X_{\texttt{mr}_i}\)</span> and <span class="math notranslate nohighlight">\(X_{\texttt{mt}_i}\)</span>) as regressors (i.e, <code class="docutils literal notranslate"><span class="pre">binary_log_model_2</span></code>).</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
\textbf{Model 1:} &amp; \\ 
&amp; h(p_i) = \log\left(\frac{p_i}{1 - p_i}\right) = \beta_0 + \beta_1 X_{\texttt{mr}_i}. \\
\textbf{Model 2:} &amp; \\ 
&amp; h(p_i) = \log\left(\frac{p_i}{1 - p_i}\right) = \beta_0 + \beta_1 X_{\texttt{mr}_i} + \beta_2 X_{\texttt{mt}_i}.
\end{align*}\end{split}\]</div>
<p>Since we are digging into model selection, we want to determine which Binary Logistic regression model fits the data better: <strong>Model 1</strong> or <strong>Model 2</strong>. Let us explore some selection techniques.</p>
<section id="analysis-of-deviance">
<h3>8.1. Analysis of Deviance<a class="headerlink" href="#analysis-of-deviance" title="Permalink to this heading">#</a></h3>
<p>The <strong>deviance</strong> (<span class="math notranslate nohighlight">\(D_k\)</span>) criterion can be used to compare a given model with <span class="math notranslate nohighlight">\(k\)</span> regressors with that of a <strong>baseline model</strong>. The usual baseline model is the <strong>saturated</strong> or <strong>full model</strong>, which perfectly fits the data because it allows a distinct probability of success <span class="math notranslate nohighlight">\(p_i\)</span> for the <span class="math notranslate nohighlight">\(i\)</span>th observation in the training dataset (<span class="math notranslate nohighlight">\(i = 1, \dots, n\)</span>), <strong>unrelated to the <span class="math notranslate nohighlight">\(k\)</span> regressors</strong>.</p>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>Given the definition of the saturated or full model under this context, we can view it as an <strong>overfitted model</strong>. Thus, we aim to avoid this type of model!</p>
</div>
<p>The <strong>maximized likelihood</strong> of this full model is denoted as <span class="math notranslate nohighlight">\(\hat{\mathscr{l}}_f\)</span>. Now, let <span class="math notranslate nohighlight">\(\hat{\mathscr{l}}_k\)</span> be the value of the maximized likelihood computed from our dataset of <span class="math notranslate nohighlight">\(n\)</span> observation with <span class="math notranslate nohighlight">\(k\)</span> regressors.</p>
<p>We can compare the fits provided by these two models by the deviance <span class="math notranslate nohighlight">\(D_k\)</span> given by</p>
<div class="math notranslate nohighlight" id="equation-deviance-general-app">
<span class="eqno">(23)<a class="headerlink" href="#equation-deviance-general-app" title="Permalink to this equation">#</a></span>\[D_k = -2 \log \left( \frac{\hat{\mathscr{l}}_k}{\hat{\mathscr{l}}_f} \right) =  -2 \left[ \log \left( \hat{\mathscr{l}}_k \right) - \log \left( \hat{\mathscr{l}}_f \right) \right].\]</div>
<p>Note that <span class="math notranslate nohighlight">\(D_k\)</span> expresses <strong>how much our given model deviates from the full model on log-likelihood scale</strong>. This metric is interpreted as follows:</p>
<ul class="simple">
<li><p><strong>Large values</strong> of <span class="math notranslate nohighlight">\(D_k\)</span> arise when <span class="math notranslate nohighlight">\(\hat{\mathscr{l}}_k\)</span> is small relative to <span class="math notranslate nohighlight">\(\hat{\mathscr{l}}_f\)</span>, indicating that <strong>our given model fits the data poorly compared to the baseline model</strong>.</p></li>
<li><p><strong>Small values</strong> of <span class="math notranslate nohighlight">\(D_k\)</span> arise when <span class="math notranslate nohighlight">\(\hat{\mathscr{l}}_k\)</span> is similar to <span class="math notranslate nohighlight">\(\hat{\mathscr{l}}_f\)</span>, indicating that <strong>our given model provides a good fit to the data compared to the baseline model</strong>.</p></li>
</ul>
<p><strong>For the specific case of the Binary Logistic regression</strong>, it can be shown that <span class="math notranslate nohighlight">\(D_k\)</span> <a class="reference internal" href="#equation-deviance-general-app">(23)</a> is represented by the following equation:</p>
<div class="math notranslate nohighlight" id="equation-deviance-bin-log">
<span class="eqno">(24)<a class="headerlink" href="#equation-deviance-bin-log" title="Permalink to this equation">#</a></span>\[\begin{equation}
D_k = -2 \sum_{i = 1}^n \left[\hat{p}_i \text{logit}(\hat{p}_i) + \log (1 - \hat{p}_i) \right],
\end{equation}\]</div>
<p>where <span class="math notranslate nohighlight">\(\hat{p}_i\)</span> is the estimated probability of success for the <span class="math notranslate nohighlight">\(i\)</span>th observation for <span class="math notranslate nohighlight">\(i = 1, \dots, n\)</span> in our training set <strong>with our fitted model of <span class="math notranslate nohighlight">\(k\)</span> regressors</strong>. Equation <a class="reference internal" href="#equation-deviance-bin-log">(24)</a> above comes from <strong>maximum likelihood estimation (MLE)</strong>.</p>
<div class="warning admonition">
<p class="admonition-title">Note</p>
<p>The mathematical proof for Equation <a class="reference internal" href="#equation-deviance-bin-log">(24)</a> can be checked in <a class="reference external" href="https://www.taylorfrancis.com/books/mono/10.1201/b16654/modelling-binary-data-david-collett">Collett (2003)</a> in Chapter 3 (Section 3.8.2).</p>
</div>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p><strong>For the specific case of Binary Logistic regression</strong>, deviance <span class="math notranslate nohighlight">\(D_k\)</span> <a class="reference internal" href="#equation-deviance-bin-log">(24)</a> cannot be used as a standalone metric of <strong>goodness of fit</strong> because of <strong>data sparsity</strong>; i.e., each <span class="math notranslate nohighlight">\(i\)</span>th observation has a different set of observed values for the <span class="math notranslate nohighlight">\(k\)</span> regressors if at least one of them is of <strong>continuous-type</strong>.</p>
<p>This data sparsity puts <span class="math notranslate nohighlight">\(D_k\)</span> just in function of the fitted probabilities <span class="math notranslate nohighlight">\(\hat{p}_i\)</span> and not on the observed values <span class="math notranslate nohighlight">\(y_i\)</span> (which tells us nothing about the agreement of our model with <span class="math notranslate nohighlight">\(k\)</span> regressors to the observed data!).</p>
</div>
<p>Still, for the case of Binary Logistic regression, we can use the analysis of deviance to perform model selection <strong>between two models where one is nested in the other</strong> (as in this example for <strong>Model 1</strong> and <strong>Model 2</strong>). So we will use our two models: <code class="docutils literal notranslate"><span class="pre">binary_log_model</span></code> with <code class="docutils literal notranslate"><span class="pre">mean_radius</span></code> as a regressor, which is nested in <code class="docutils literal notranslate"><span class="pre">binary_log_model_2</span></code> with <code class="docutils literal notranslate"><span class="pre">mean_radius</span></code> and <code class="docutils literal notranslate"><span class="pre">mean_texture</span></code> as regressors.</p>
<p>This specific model selection will involve a hypothesis testing. The hypotheses are:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{gather*}
H_0: \textbf{Model 1} \text{ fits the data better than } \textbf{Model 2} \\
H_a: \textbf{Model 2} \text{ fits the data better than } \textbf{Model 1}.
\end{gather*}\end{split}\]</div>
<p>We have to use the multipurpose function <code class="docutils literal notranslate"><span class="pre">anova()</span></code> in the following way:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">round</span><span class="p">(</span><span class="nf">anova</span><span class="p">(</span><span class="n">binary_log_model</span><span class="p">,</span>
<span class="w">  </span><span class="n">binary_log_model_2</span><span class="p">,</span>
<span class="w">  </span><span class="n">test</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Chi&quot;</span>
<span class="p">),</span><span class="w"> </span><span class="m">4</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="dataframe">
<caption>A anova: 2 × 5</caption>
<thead>
	<tr><th></th><th scope=col>Resid. Df</th><th scope=col>Resid. Dev</th><th scope=col>Df</th><th scope=col>Deviance</th><th scope=col>Pr(&gt;Chi)</th></tr>
	<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>
</thead>
<tbody>
	<tr><th scope=row>1</th><td>567</td><td>330.0108</td><td>NA</td><td>     NA</td><td>NA</td></tr>
	<tr><th scope=row>2</th><td>566</td><td>291.1233</td><td> 1</td><td>38.8875</td><td> 0</td></tr>
</tbody>
</table>
</div></div>
</div>
<p>Let <span class="math notranslate nohighlight">\(D_2\)</span> be the deviance (column <code class="docutils literal notranslate"><span class="pre">Resid.</span> <span class="pre">Dev</span></code>) for <strong>Model 2</strong> (<code class="docutils literal notranslate"><span class="pre">binary_log_model_2</span></code>) in row 2 and <span class="math notranslate nohighlight">\(D_1\)</span> (column <code class="docutils literal notranslate"><span class="pre">Resid.</span> <span class="pre">Dev</span></code>) the deviance for <strong>Model 1</strong> (<code class="docutils literal notranslate"><span class="pre">binary_log_model</span></code>) in row 1. The <strong>test statistic</strong> <span class="math notranslate nohighlight">\(\Delta_D\)</span> (column <code class="docutils literal notranslate"><span class="pre">Deviance</span></code>) for the analysis of deviance is given by:</p>
<div class="math notranslate nohighlight">
\[
\Delta_D = D_1 - D_2 \sim \chi^2_{1},
\]</div>
<p>which <strong>assymptotically</strong> (i.e., <span class="math notranslate nohighlight">\(n \rightarrow \infty\)</span>) is <a class="reference external" href="https://www.math.wm.edu/~leemis/chart/UDR/PDFs/Chisquare.pdf"><strong>Chi-squared distributed</strong></a> with <span class="math notranslate nohighlight">\(1\)</span> degree of freedom (column <code class="docutils literal notranslate"><span class="pre">Df</span></code>) under <span class="math notranslate nohighlight">\(H_0\)</span> <strong>for this specific case</strong>.</p>
<p>We obtain a <span class="math notranslate nohighlight">\(p\text{-value} &lt; .001\)</span>, column <code class="docutils literal notranslate"><span class="pre">Pr(&gt;Chi)</span></code>, which gives us evidence to reject <span class="math notranslate nohighlight">\(H_0\)</span>. Hence, <strong>we have evidence</strong> to conclude that <code class="docutils literal notranslate"><span class="pre">binary_log_model_2</span></code> fits the data better than <code class="docutils literal notranslate"><span class="pre">binary_log_model</span></code>. Therefore, <strong>in the context of model selection</strong>, adding <code class="docutils literal notranslate"><span class="pre">mean_texture</span></code> provides a better fitted model. Hence, we would choose <code class="docutils literal notranslate"><span class="pre">binary_log_model_2</span></code>.</p>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>In general, the degrees of freedom are the <strong>regression parameters of difference between both models</strong>, which is <span class="math notranslate nohighlight">\(1\)</span> in this example given that <strong>Model 2</strong> has an additional parameter <span class="math notranslate nohighlight">\(\beta_2\)</span>.</p>
<p>Formally, this nested hypothesis testing is called the <strong>likelihood-ratio test</strong>.</p>
</div>
</section>
<section id="akaike-information-criterion">
<h3>8.2. Akaike Information Criterion<a class="headerlink" href="#akaike-information-criterion" title="Permalink to this heading">#</a></h3>
<p><strong>One of the drawbacks of the analysis of deviance</strong> is that it only allows to test <strong>nested</strong> regression models when we have sparse data (i.e., each response is associated with a different set of values in the regressors).</p>
<p>Fortunately, we have alternatives for model selection. <strong>The Akaike Information Criterion (AIC) makes possible to compare models that are either nested or not.</strong> For a model with <span class="math notranslate nohighlight">\(k\)</span> model terms and a deviance <span class="math notranslate nohighlight">\(D_k\)</span> is defined as:</p>
<div class="math notranslate nohighlight">
\[\begin{equation}
\mbox{AIC}_k = D_k + 2k.
\end{equation}\]</div>
<p>Models with <strong>smaller</strong> values of <span class="math notranslate nohighlight">\(\mbox{AIC}_k\)</span> are preferred. That said, <span class="math notranslate nohighlight">\(\mbox{AIC}_k\)</span> favours models with small values of <span class="math notranslate nohighlight">\(D_k\)</span>.</p>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>However, <span class="math notranslate nohighlight">\(\mbox{AIC}_k\)</span> penalizes for including more regressors in the model. Hence, it discourages overfitting, which is key in model selection.</p>
<p>This is why we select that model with the smallest <span class="math notranslate nohighlight">\(\mbox{AIC}_k\)</span>.</p>
</div>
<p>The function <code class="docutils literal notranslate"><span class="pre">glance()</span></code> shows us the <span class="math notranslate nohighlight">\(\mbox{AIC}_k\)</span> by model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">glance</span><span class="p">(</span><span class="n">binary_log_model</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="nf">mutate_if</span><span class="p">(</span><span class="n">is.numeric</span><span class="p">,</span><span class="w"> </span><span class="n">round</span><span class="p">,</span><span class="w"> </span><span class="m">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="dataframe">
<caption>A tibble: 1 × 8</caption>
<thead>
	<tr><th scope=col>null.deviance</th><th scope=col>df.null</th><th scope=col>logLik</th><th scope=col>AIC</th><th scope=col>BIC</th><th scope=col>deviance</th><th scope=col>df.residual</th><th scope=col>nobs</th></tr>
	<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>
</thead>
<tbody>
	<tr><td>751.44</td><td>568</td><td>-165.005</td><td>334.011</td><td>342.699</td><td>330.011</td><td>567</td><td>569</td></tr>
</tbody>
</table>
</div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">glance</span><span class="p">(</span><span class="n">binary_log_model_2</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="nf">mutate_if</span><span class="p">(</span><span class="n">is.numeric</span><span class="p">,</span><span class="w"> </span><span class="n">round</span><span class="p">,</span><span class="w"> </span><span class="m">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="dataframe">
<caption>A tibble: 1 × 8</caption>
<thead>
	<tr><th scope=col>null.deviance</th><th scope=col>df.null</th><th scope=col>logLik</th><th scope=col>AIC</th><th scope=col>BIC</th><th scope=col>deviance</th><th scope=col>df.residual</th><th scope=col>nobs</th></tr>
	<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>
</thead>
<tbody>
	<tr><td>751.44</td><td>568</td><td>-145.562</td><td>297.123</td><td>310.155</td><td>291.123</td><td>566</td><td>569</td></tr>
</tbody>
</table>
</div></div>
</div>
<blockquote>
<div><p>Following the results of the above <code class="docutils literal notranslate"><span class="pre">AIC</span></code> columns, we choose <code class="docutils literal notranslate"><span class="pre">binary_log_model_2</span></code> over <code class="docutils literal notranslate"><span class="pre">binary_log_model</span></code>.</p>
</div></blockquote>
</section>
<section id="bayesian-information-criterion">
<h3>8.3. Bayesian Information Criterion<a class="headerlink" href="#bayesian-information-criterion" title="Permalink to this heading">#</a></h3>
<p>An alternative to AIC is the Bayesian Information Criterion (BIC). <strong>The BIC also makes possible to compare models that are either nested or not.</strong> For a model with <span class="math notranslate nohighlight">\(k\)</span> regressors, <span class="math notranslate nohighlight">\(n\)</span> observations used for training, and a deviance <span class="math notranslate nohighlight">\(D_k\)</span>; it is defined as:</p>
<div class="math notranslate nohighlight">
\[\mbox{BIC}_k = D_k + k \log (n).\]</div>
<p>Models with <strong>smaller</strong> values of <span class="math notranslate nohighlight">\(\mbox{BIC}_k\)</span> are preferred. That said, <span class="math notranslate nohighlight">\(\mbox{BIC}_k\)</span> also favours models with small values of <span class="math notranslate nohighlight">\(D_k\)</span>.</p>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>The differences between AIC and BIC will be more pronounced in datasets with large sample sizes <span class="math notranslate nohighlight">\(n\)</span>. As the BIC penalty of <span class="math notranslate nohighlight">\(k \log (n)\)</span> will always be larger than the AIC penalty of <span class="math notranslate nohighlight">\(2k\)</span> when <span class="math notranslate nohighlight">\(n &gt; 7\)</span>, <strong>BIC tends to select models with fewer regressors than AIC</strong>.</p>
</div>
<blockquote>
<div><p>Following the results of the <code class="docutils literal notranslate"><span class="pre">BIC</span></code> column above, we also choose <code class="docutils literal notranslate"><span class="pre">binary_log_model_2</span></code> over <code class="docutils literal notranslate"><span class="pre">binary_log_model</span></code> (column <code class="docutils literal notranslate"><span class="pre">BIC</span></code>).</p>
</div></blockquote>
</section>
</section>
<section id="optional-9-model-diagnostics">
<h2>(Optional) 9. Model Diagnostics<a class="headerlink" href="#optional-9-model-diagnostics" title="Permalink to this heading">#</a></h2>
<p><strong>Model diagnostics</strong> in GLMs are not the same ones from OLS regression and <strong>there is still an open research field for them</strong>. We will check two different plots for the Binary Logistic regression model.</p>
<section id="deviance-residuals">
<h3>9.1. Deviance Residuals<a class="headerlink" href="#deviance-residuals" title="Permalink to this heading">#</a></h3>
<p>We can obtain more than one class of residual in a Binary Logistic regression. However, we will concentrate on the <strong>deviance residuals</strong>. A deviance residual for the <span class="math notranslate nohighlight">\(i\)</span>th binary observation <span class="math notranslate nohighlight">\(y_i\)</span> is defined as:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
d_i=
\begin{cases}
\sqrt{-2 \log \hat{p}_i} \; \; \; \; \mbox{if $y_i = 1$},\\
-\sqrt{-2 \log (1 - \hat{p}_i}) \; \; \; \; \mbox{if $y_i = 0$}.
\end{cases}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(\hat{p}_i\)</span> is the predicted probability of success coming from the model.</p>
<p>The sum all the <span class="math notranslate nohighlight">\(n\)</span> <span class="math notranslate nohighlight">\(d_i\)</span>s in the model is the deviance <span class="math notranslate nohighlight">\(D_k\)</span> (column <code class="docutils literal notranslate"><span class="pre">deviance</span></code> below via function <code class="docutils literal notranslate"><span class="pre">glance()</span></code> by model).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">glance</span><span class="p">(</span><span class="n">binary_log_model</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="nf">mutate_if</span><span class="p">(</span><span class="n">is.numeric</span><span class="p">,</span><span class="w"> </span><span class="n">round</span><span class="p">,</span><span class="w"> </span><span class="m">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="dataframe">
<caption>A tibble: 1 × 8</caption>
<thead>
	<tr><th scope=col>null.deviance</th><th scope=col>df.null</th><th scope=col>logLik</th><th scope=col>AIC</th><th scope=col>BIC</th><th scope=col>deviance</th><th scope=col>df.residual</th><th scope=col>nobs</th></tr>
	<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>
</thead>
<tbody>
	<tr><td>751.44</td><td>568</td><td>-165.005</td><td>334.011</td><td>342.699</td><td>330.011</td><td>567</td><td>569</td></tr>
</tbody>
</table>
</div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">glance</span><span class="p">(</span><span class="n">binary_log_model_2</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="nf">mutate_if</span><span class="p">(</span><span class="n">is.numeric</span><span class="p">,</span><span class="w"> </span><span class="n">round</span><span class="p">,</span><span class="w"> </span><span class="m">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="dataframe">
<caption>A tibble: 1 × 8</caption>
<thead>
	<tr><th scope=col>null.deviance</th><th scope=col>df.null</th><th scope=col>logLik</th><th scope=col>AIC</th><th scope=col>BIC</th><th scope=col>deviance</th><th scope=col>df.residual</th><th scope=col>nobs</th></tr>
	<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>
</thead>
<tbody>
	<tr><td>751.44</td><td>568</td><td>-145.562</td><td>297.123</td><td>310.155</td><td>291.123</td><td>566</td><td>569</td></tr>
</tbody>
</table>
</div></div>
</div>
<p>With a large enough sample size <span class="math notranslate nohighlight">\(n\)</span>, the deviance residuals are approximately normally distributed. Hence, we could use <strong><span class="math notranslate nohighlight">\(Q\)</span>-<span class="math notranslate nohighlight">\(Q\)</span> plots</strong> for both models. To deliver these <span class="math notranslate nohighlight">\(Q\)</span>-<span class="math notranslate nohighlight">\(Q\)</span> plots, we need to extract the deviance residuals from the Binary Logistic regression models. We can do it via the function <code class="docutils literal notranslate"><span class="pre">residuals()</span></code> with the argument <code class="docutils literal notranslate"><span class="pre">type</span> <span class="pre">=</span> <span class="pre">&quot;deviance&quot;</span></code>. Below you can find the code to extract these residuals from <code class="docutils literal notranslate"><span class="pre">binary_log_model</span></code> and <code class="docutils literal notranslate"><span class="pre">binary_log_model_2</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">binary_log_model_dev_residuals</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">data.frame</span><span class="p">(</span><span class="n">dev_residuals</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">residuals</span><span class="p">(</span><span class="n">binary_log_model</span><span class="p">,</span><span class="w"> </span><span class="n">type</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;deviance&quot;</span><span class="p">))</span>
<span class="n">binary_log_model_dev_residuals</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="dataframe">
<caption>A data.frame: 569 × 1</caption>
<thead>
	<tr><th></th><th scope=col>dev_residuals</th></tr>
	<tr><th></th><th scope=col>&lt;dbl&gt;</th></tr>
</thead>
<tbody>
	<tr><th scope=row>1</th><td>0.26282111</td></tr>
	<tr><th scope=row>2</th><td>0.06983906</td></tr>
	<tr><th scope=row>3</th><td>0.10995490</td></tr>
	<tr><th scope=row>⋮</th><td>⋮</td></tr>
	<tr><th scope=row>567</th><td> 0.52511283</td></tr>
	<tr><th scope=row>568</th><td> 0.06876592</td></tr>
	<tr><th scope=row>569</th><td>-0.03815040</td></tr>
</tbody>
</table>
</div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">binary_log_model_2_dev_residuals</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">data.frame</span><span class="p">(</span><span class="n">dev_residuals</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">residuals</span><span class="p">(</span><span class="n">binary_log_model_2</span><span class="p">,</span><span class="w"> </span><span class="n">type</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;deviance&quot;</span><span class="p">))</span>
<span class="n">binary_log_model_2_dev_residuals</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="dataframe">
<caption>A data.frame: 569 × 1</caption>
<thead>
	<tr><th></th><th scope=col>dev_residuals</th></tr>
	<tr><th></th><th scope=col>&lt;dbl&gt;</th></tr>
</thead>
<tbody>
	<tr><th scope=row>1</th><td>0.65442997</td></tr>
	<tr><th scope=row>2</th><td>0.07886868</td></tr>
	<tr><th scope=row>3</th><td>0.08590128</td></tr>
	<tr><th scope=row>⋮</th><td>⋮</td></tr>
	<tr><th scope=row>567</th><td> 0.20788406</td></tr>
	<tr><th scope=row>568</th><td> 0.02201645</td></tr>
	<tr><th scope=row>569</th><td>-0.06078262</td></tr>
</tbody>
</table>
</div></div>
</div>
<p>We can code these plots “by hand” using <code class="docutils literal notranslate"><span class="pre">ggplot2()</span></code>, but we will save up time using package <code class="docutils literal notranslate"><span class="pre">qqplotr</span></code>. The file <code class="docutils literal notranslate"><span class="pre">support_functions.R</span></code> in the repo’s folder <code class="docutils literal notranslate"><span class="pre">scripts</span></code> contains the function <code class="docutils literal notranslate"><span class="pre">qqplot_dev_residuals()</span></code>, which uses <code class="docutils literal notranslate"><span class="pre">qqplotr</span></code>’s tools. This function shows the <span class="math notranslate nohighlight">\(Q\)</span>-<span class="math notranslate nohighlight">\(Q\)</span> plot for the deviance residuals of each fitted model. It needs these residuals in the <code class="docutils literal notranslate"><span class="pre">data</span></code> argument and a proper <code class="docutils literal notranslate"><span class="pre">title</span></code>.</p>
<p>The advantage of <code class="docutils literal notranslate"><span class="pre">qqplotr</span></code> is that, besides the usual 45° degree line, it allows us to plot 95% (by default) <strong>confidence bands</strong>. Since we cannot expect all points to be on the 45° degree line, we still expect them to be within the confidence bands. <strong>Nonetheless, we have serious non-normality issues on both models for the most extreme observations, as shown below.</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">qqplot_dev_residuals</span><span class="p">(</span>
<span class="w">  </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">binary_log_model_dev_residuals</span><span class="p">,</span>
<span class="w">  </span><span class="n">title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Q-Q Plot for Binary Logistic Model with Mean Radius&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/9b71f27a0d4c8b4e89a7a11c23316b04e6e53dd08db9b3393459a056b0a55a8f.png" src="../_images/9b71f27a0d4c8b4e89a7a11c23316b04e6e53dd08db9b3393459a056b0a55a8f.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">qqplot_dev_residuals</span><span class="p">(</span>
<span class="w">  </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">binary_log_model_2_dev_residuals</span><span class="p">,</span>
<span class="w">  </span><span class="n">title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Q-Q Plot for Binary Logistic Model with Mean Radius and Mean Texture&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/7e0e4ca1f6597e834d5d231316223f4dfdec1e9087398fe844d6358e940249f2.png" src="../_images/7e0e4ca1f6597e834d5d231316223f4dfdec1e9087398fe844d6358e940249f2.png" />
</div>
</div>
</section>
<section id="binned-residual-plots">
<h3>9.2. Binned Residual Plots<a class="headerlink" href="#binned-residual-plots" title="Permalink to this heading">#</a></h3>
<p>A plot of <strong>the deviance residuals <span class="math notranslate nohighlight">\(d_i\)</span> versus fitted values <span class="math notranslate nohighlight">\(\mbox{logit}(p_i)\)</span></strong> (as the one below for <code class="docutils literal notranslate"><span class="pre">binary_log_model_2</span></code>) might not be too informative. This class of diagnostic plot makes sense for OLS to verify we are fulfilling <strong>the constant variance assumption</strong> on the random component. Nevertheless, it is not the case for Binary Logistic regression <strong>since each response is an independent Bernoulli trial with its parameter <span class="math notranslate nohighlight">\(p_i\)</span></strong>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">plot</span><span class="p">(</span><span class="n">binary_log_model_2</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">cex.lab</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1.5</span><span class="p">,</span><span class="w"> </span><span class="n">cex.axis</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1.5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/2e99039a009f1a54249314e198eaec7be22cc274c445f8a183a0c4df043562e2.png" src="../_images/2e99039a009f1a54249314e198eaec7be22cc274c445f8a183a0c4df043562e2.png" />
</div>
</div>
<p>Besides deviance residuals, the Binary Logistic regression model has the <span class="math notranslate nohighlight">\(i\)</span>th <strong>raw residual</strong> <span class="math notranslate nohighlight">\(r_i\)</span> as the difference between the binary observed <span class="math notranslate nohighlight">\(y_i\)</span> and the fitted value <span class="math notranslate nohighlight">\(\hat{p}_i\)</span>:</p>
<div class="math notranslate nohighlight">
\[
r_i = y_i - \hat{p}_i \in [-1, 1]
\]</div>
<p><a class="reference external" href="http://webcat2.library.ubc.ca/vwebv/search?searchArg=Data%20analysis%20using%20regression%20and%20multilevel%2Fhierarchical%20models%20%2F&amp;searchCode=TALL&amp;searchType=1">Gelman and Hill (2007)</a> recommend using <strong>binned residual plots</strong>. These plots are available via the package <code class="docutils literal notranslate"><span class="pre">performance</span></code> and its function <code class="docutils literal notranslate"><span class="pre">binned_residuals()</span></code>. Its argument is the fitted model as in the code below. The output is a data frame used to build the corresponding diagnostic plot.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">diagnostic_bins</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">binned_residuals</span><span class="p">(</span><span class="n">binary_log_model_2</span><span class="p">)</span>
<span class="n">diagnostic_bins</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="dataframe">
<caption>A binned_residuals: 24 × 9</caption>
<thead>
	<tr><th></th><th scope=col>xbar</th><th scope=col>ybar</th><th scope=col>n</th><th scope=col>x.lo</th><th scope=col>x.hi</th><th scope=col>se</th><th scope=col>CI_low</th><th scope=col>CI_high</th><th scope=col>group</th></tr>
	<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th></tr>
</thead>
<tbody>
	<tr><th scope=row>conf_int</th><td>0.0009379625</td><td>-0.04178677</td><td>23</td><td>7.190053e-05</td><td>0.001845559</td><td>0.004780543</td><td>-0.1158793</td><td> 0.032305796</td><td>no</td></tr>
	<tr><th scope=row>conf_int1</th><td>0.0030236387</td><td>-0.07712111</td><td>24</td><td>1.897157e-03</td><td>0.004319643</td><td>0.004275154</td><td>-0.1483579</td><td>-0.005884315</td><td>no</td></tr>
	<tr><th scope=row>conf_int2</th><td>0.0054739696</td><td>-0.10450147</td><td>24</td><td>4.374413e-03</td><td>0.007189815</td><td>0.003115474</td><td>-0.1757383</td><td>-0.033264675</td><td>no</td></tr>
	<tr><th scope=row>⋮</th><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td></tr>
	<tr><th scope=row>conf_int21</th><td>0.9953239</td><td>0.09486664</td><td>24</td><td>0.9918863</td><td>0.9973316</td><td>0.007948755</td><td> 0.02362984</td><td>0.1661034</td><td>no</td></tr>
	<tr><th scope=row>conf_int22</th><td>0.9986466</td><td>0.05095846</td><td>24</td><td>0.9976117</td><td>0.9994714</td><td>0.004327612</td><td>-0.02027833</td><td>0.1221953</td><td>no</td></tr>
	<tr><th scope=row>conf_int23</th><td>0.9998101</td><td>0.01630470</td><td>24</td><td>0.9994960</td><td>0.9999997</td><td>0.004362187</td><td>-0.05493210</td><td>0.0875415</td><td>no</td></tr>
</tbody>
</table>
</div></div>
</div>
<p>Then, we can obtain the binned residual plot via the function <code class="docutils literal notranslate"><span class="pre">plot()</span></code>. The resulting plot is a <code class="docutils literal notranslate"><span class="pre">ggplot</span></code> object.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">plot</span><span class="p">(</span><span class="n">diagnostic_bins</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">theme</span><span class="p">(</span>
<span class="w">    </span><span class="n">plot.title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">element_text</span><span class="p">(</span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">30</span><span class="p">,</span><span class="w"> </span><span class="n">face</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;bold&quot;</span><span class="p">),</span>
<span class="w">    </span><span class="n">plot.subtitle</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">element_text</span><span class="p">(</span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">23</span><span class="p">),</span><span class="w"> </span>
<span class="w">    </span><span class="n">axis.text</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">element_text</span><span class="p">(</span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">21</span><span class="p">),</span>
<span class="w">    </span><span class="n">axis.title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">element_text</span><span class="p">(</span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">27</span><span class="p">),</span>
<span class="w">    </span><span class="n">legend.text</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">element_text</span><span class="p">(</span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">21</span><span class="p">),</span>
<span class="w">    </span><span class="n">legend.title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">element_text</span><span class="p">(</span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">21</span><span class="p">,</span><span class="w"> </span><span class="n">face</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;bold&quot;</span><span class="p">)</span>
<span class="w">  </span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/2cf10c46bd1098fa551d637db3a45fa91b443dcb15240366819955e9c92df65e.png" src="../_images/2cf10c46bd1098fa551d637db3a45fa91b443dcb15240366819955e9c92df65e.png" />
</div>
</div>
<p>The plot above corresponds to <code class="docutils literal notranslate"><span class="pre">binary_log_model_2</span></code>. Function <code class="docutils literal notranslate"><span class="pre">binned_residuals()</span></code> does the following:</p>
<ul class="simple">
<li><p><strong>Unless specified</strong>, the <strong>default number of bins</strong> is <span class="math notranslate nohighlight">\(\lceil \sqrt{n} \rceil\)</span> as in the ceiling function: <code class="docutils literal notranslate"><span class="pre">ceiling(sqrt(n))</span></code>. For the dataset <code class="docutils literal notranslate"><span class="pre">breast_cancer</span></code> we have <span class="math notranslate nohighlight">\(n = 569\)</span>, leading to 24 bins (i.e. 24 points in the plot).</p></li>
<li><p>The <span class="math notranslate nohighlight">\(n\)</span> <strong>fitted values</strong> <span class="math notranslate nohighlight">\(\hat{p}_i\)</span> are ordered from smallest to largest.</p></li>
<li><p>The ordered fitted values <span class="math notranslate nohighlight">\(\hat{p}_1 &lt; \hat{p}_2 &lt; \dots &lt; \hat{p}_n\)</span> are equally split in the <span class="math notranslate nohighlight">\(\lceil \sqrt(n) \rceil\)</span> bins.</p></li>
<li><p>The respective average fitted value per bin is mapped onto the <span class="math notranslate nohighlight">\(x\)</span>-axis.</p></li>
<li><p>The corresponding average raw residual <span class="math notranslate nohighlight">\(\bar{r}_j\)</span> for the <span class="math notranslate nohighlight">\(j\)</span>th bin is mapped on the <span class="math notranslate nohighlight">\(y\)</span>-axis. Recall the <span class="math notranslate nohighlight">\(i\)</span>th raw residual is <span class="math notranslate nohighlight">\(r_i = y_i - \hat{p}_i\)</span>.</p></li>
<li><p>The <strong>95% bounds of confidence</strong> are computed as <span class="math notranslate nohighlight">\(\pm 1.96 \times \left( \frac{s_{r_j}}{\sqrt{n_j}} \right)\)</span> <strong>centred at <span class="math notranslate nohighlight">\(0\)</span> on the <span class="math notranslate nohighlight">\(y\)</span>-axis</strong>; where <span class="math notranslate nohighlight">\(s_{r_j}\)</span> is the <strong>sample standard deviation</strong> of the raw residuals in the <span class="math notranslate nohighlight">\(j\)</span>th bin with <span class="math notranslate nohighlight">\(n_j\)</span> observations, and <span class="math notranslate nohighlight">\(1.96\)</span> is the <span class="math notranslate nohighlight">\(97.5th\)</span> percentile of the Standard Normal distribution.</p></li>
<li><p><strong>One would expect to have <span class="math notranslate nohighlight">\(95\%\)</span> of the points to be within the bounds to have a good model fit.</strong> We can check this via the below code on column <code class="docutils literal notranslate"><span class="pre">group</span></code> in <code class="docutils literal notranslate"><span class="pre">diagnostic_bins</span></code>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">prop.table</span><span class="p">(</span><span class="nf">table</span><span class="p">(</span><span class="nf">as.factor</span><span class="p">(</span><span class="n">diagnostic_bins</span><span class="o">$</span><span class="n">group</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>       no       yes 
0.5416667 0.4583333 
</pre></div>
</div>
</div>
</div>
<p>Therefore, using a binned residual plot for <code class="docutils literal notranslate"><span class="pre">binary_log_model_2</span></code>, we can conclude this model is not a good for our training data.</p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "r"
        },
        kernelOptions: {
            name: "ir",
            path: "./notes"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'ir'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="lecture8_missing_data.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Lecture 8 - Missing Data</p>
      </div>
    </a>
    <a class="right-next"
       href="appendix-reg-cheatsheet.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Regression Cheatsheet</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#loading-libraries">Loading Libraries</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-breast-cancer-dataset">1. The Breast Cancer Dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-modelling-framework">2. Data Modelling Framework</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#using-ordinary-least-squares-to-model-probabilities">2.1. Using Ordinary Least-Squares to Model Probabilities</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-logit-function">2.2. The Logit Function</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#general-modelling-framework">2.3. General Modelling Framework</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#estimation">3. Estimation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#inference">4. Inference</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#coefficient-interpretation">5. Coefficient Interpretation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#predictions">7. Predictions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-selection">8. Model Selection</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#analysis-of-deviance">8.1. Analysis of Deviance</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#akaike-information-criterion">8.2. Akaike Information Criterion</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesian-information-criterion">8.3. Bayesian Information Criterion</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#optional-9-model-diagnostics">(Optional) 9. Model Diagnostics</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#deviance-residuals">9.1. Deviance Residuals</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#binned-residual-plots">9.2. Binned Residual Plots</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By G. Alexi Rodríguez-Arelis, Rodolfo Lourenzutti, and Vincenzo Coia
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>